{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB7kMbQOxKk7"
      },
      "source": [
        "# 0. Setup\n",
        "In this section, we import all necessary libraries and set up our environment for reproducibility and performance. We will:\n",
        "Install and import required packages (e.g., scikit-learn, XGBoost, LightGBM, TensorFlow, Hugging Face Transformers, etc.).\n",
        "Configure global settings, such as random seeds for reproducibility.\n",
        "Detect hardware accelerators (GPU/TPU) and set computation device accordingly.\n",
        "Define any global constants or configuration dictionaries (e.g., for preprocessing options, model toggles).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_rRKb5E5SOv"
      },
      "source": [
        "## 0.1 Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9L8ySMUz5Y8J",
        "outputId": "c0daffb3-ba5d-46b7-f79f-876ab0d85b8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q lightgbm xgboost transformers plotly gensim"
      ],
      "metadata": {
        "id": "O61P_CccjRks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP7dwdP7g_SZ"
      },
      "source": [
        "## 0.2 Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIEKfGdEg-rm"
      },
      "outputs": [],
      "source": [
        "# Imports for data manipulation and visualization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "\n",
        "\n",
        "# Imports for text preprocessing and NLP\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import gensim.downloader as api\n",
        "# Machine Learning models and utilities\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_predict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC as SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, StackingClassifier, VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# Deep Learning (Keras and Transformers)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import torch\n",
        "# Other utilities\n",
        "import os, sys, time\n",
        "import logging\n",
        "from sklearn.utils import class_weight"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloads\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAX1-zfQZRKd",
        "outputId": "713f156c-2adb-410b-bb9e-f2f26c2e0a68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13D4dYeN4Nxv"
      },
      "source": [
        "## 0.3 Dataset Download\n",
        "Our primary working environment for this coursework is in Google Collab.\n",
        " Storage in Google Colab primarily works on session storage or mounted google drives.\n",
        " This is very inconvenient we instead curl in the datasets for ease of **use**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DN36dAxX4TLT",
        "outputId": "ca130743-a7b4-461e-ca7e-e1fd821e70c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1pA7Mds0D_Y4hbBe8ShznH5rxWfds9nex\n",
            "From (redirected): https://drive.google.com/uc?id=1pA7Mds0D_Y4hbBe8ShznH5rxWfds9nex&confirm=t&uuid=3b2692a5-e140-4f2f-8dff-331b3ed3198e\n",
            "To: /content/amazon_reviews_complete.csv\n",
            "100% 136M/136M [00:00<00:00, 137MB/s]\n"
          ]
        }
      ],
      "source": [
        "# download dataset\n",
        "!gdown --id 1pA7Mds0D_Y4hbBe8ShznH5rxWfds9nex -O amazon_reviews_complete.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPY2Fp2N5sh_",
        "outputId": "8f14add6-82eb-4c7f-f2f2-a097b3c0bb06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sHl5dIaPgICQyNZiCImmiU_wCBMHYMuI\n",
            "To: /content/amazon_reviews_submission.csv\n",
            "100% 53.3M/53.3M [00:00<00:00, 106MB/s]\n"
          ]
        }
      ],
      "source": [
        "# download submission set\n",
        "!gdown --id 1sHl5dIaPgICQyNZiCImmiU_wCBMHYMuI -O amazon_reviews_submission.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0.4 Environment Configuration"
      ],
      "metadata": {
        "id": "aTs-4JXD3UKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# Check for GPU availability and set device\n",
        "USE_GPU = False\n",
        "device = \"cpu\"\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    USE_GPU = True\n",
        "    device = \"GPU\"\n",
        "elif tf.config.list_physical_devices('TPU'):\n",
        "    device = \"TPU\"\n",
        "print(f\"Running on {device}\")\n",
        "\n",
        "# Configuration for text preprocessing\n",
        "PREPROCESS_CONFIG = {\n",
        "    \"lowercase\": True,\n",
        "    \"remove_html\": True,\n",
        "    \"remove_markdown\": True,\n",
        "    \"remove_stopwords\": True,\n",
        "    \"lemmatize\": False,\n",
        "    \"stem\": False   # Note: Use either lemmatize or stem, not both simultaneously for best results.\n",
        "}\n",
        "\n",
        "# Optionally sample a fraction of data for quicker runs (set to None or 1.0 to use full data)\n",
        "SAMPLING_FRACTION = None  # e.g., 0.1 for 10% sample, or None to use all data\n",
        "\n",
        "# Toggle for class imbalance handling\n",
        "BALANCE_CLASSES = True  # if True, models that support class_weight will use it, or we may oversample in preprocessing\n",
        "\n",
        "# Path to dataset\n",
        "DATA_PATH = \"amazon_reviews_complete.csv\"\n",
        "\n",
        "\n",
        "if USE_GPU:\n",
        "    # For TensorFlow\n",
        "    if device == \"GPU\":\n",
        "        tf.config.optimizer.set_jit(True)  # Enable XLA compilation\n",
        "        tf.config.set_soft_device_placement(True)\n",
        "        policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "        tf.keras.mixed_precision.set_global_policy(policy)\n",
        "\n",
        "    # For PyTorch (Transformers)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.autograd.profiler.emit_nvtx(False)\n",
        "    torch.autograd.profiler.profile(False)\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'\n",
        "tf.get_logger().setLevel('INFO')"
      ],
      "metadata": {
        "id": "amcBgdcT3W-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36179823-a098-4a0e-925d-5d1351a0a98a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configurable options for preprocessing and modeling: We define dictionaries to control behavior of various pipeline stages. For example:\n",
        "PREPROCESS_CONFIG: toggles for text cleaning (lowercasing, removing HTML/markdown, stopwords, lemmatization, stemming).\n",
        "SAMPLING_FRACTION: fraction of data to sample for faster execution (if needed for large datasets).\n",
        "BALANCE_CLASSES: whether to apply class balancing techniques (e.g., class weights in models)."
      ],
      "metadata": {
        "id": "Ylq6MyT2g-KL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Loading and Sampling\n",
        "Here we load the Amazon food reviews dataset and prepare it for analysis. The dataset is expected at the path 'amazon_reviews_complete.csv' and contains at least two columns:\n",
        "- Text: The review text content.\n",
        "- Score: The rating (1 to 5 stars) given to the product.\n",
        "Steps in this section:\n",
        "- Read the CSV data into a pandas DataFrame.\n",
        "- If SAMPLING_FRACTION is set (for performance), sample that fraction of the data randomly to reduce size.\n",
        "- Display basic information: number of reviews, columns, and a preview of the data.\n",
        "- Check distribution of the target Score (class imbalance insight)."
      ],
      "metadata": {
        "id": "OkVAuMhzg5eE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: {e}\\nPlease ensure the dataset is available at {DATA_PATH}\")\n",
        "\n",
        "# Optionally sample the data for faster computation (especially if dataset is very large)\n",
        "if SAMPLING_FRACTION is not None and 0 < SAMPLING_FRACTION < 1.0:\n",
        "    df = df.sample(frac=SAMPLING_FRACTION, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "# Basic dataset info\n",
        "print(f\"Total reviews loaded: {len(df)}\")\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "print(df.head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW6XpJ3jhHQa",
        "outputId": "553126c4-278a-4f98-f47f-64d4c2bcc067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total reviews loaded: 309131\n",
            "Columns: ['Score', 'Text']\n",
            "   Score                                               Text\n",
            "0      5  I received this product early from the seller!...\n",
            "1      5  *****<br />Numi's Collection Assortment Melang...\n",
            "2      5  I was very careful not to overcook this pasta,...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's examine the distribution of review scores to understand class imbalance. If one score dominates (e.g., many 5-star reviews), we'll need to address that in modeling (using class weights or resampling)."
      ],
      "metadata": {
        "id": "Ld2pv5FGhTb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check class distribution\n",
        "score_counts = df['Score'].value_counts().sort_index()\n",
        "print(\"Review score distribution:\")\n",
        "for score, count in score_counts.items():\n",
        "    print(f\"  Score {score}: {count} reviews\")\n",
        "\n",
        "# Visualize the class distribution\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.barplot(x=score_counts.index, y=score_counts.values, palette=\"viridis\")\n",
        "plt.title(\"Distribution of Review Ratings (1-5 stars)\")\n",
        "plt.xlabel(\"Review Score\")\n",
        "plt.ylabel(\"Count of Reviews\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "CIMtTKHYhVCI",
        "outputId": "c714c31b-7db6-4129-f405-844b3f085db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review score distribution:\n",
            "  Score 1: 28521 reviews\n",
            "  Score 2: 16287 reviews\n",
            "  Score 3: 23296 reviews\n",
            "  Score 4: 43876 reviews\n",
            "  Score 5: 197151 reviews\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-0c379968489f>:9: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=score_counts.index, y=score_counts.values, palette=\"viridis\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Exploratory Data Analysis (EDA) with Visualizations\n",
        "In this section, we perform exploratory analysis to gain insights from the text data and ratings:\n",
        "- Review Text Lengths: Analyze the distribution of review lengths (number of words or characters).\n",
        "- Common Words or N-grams: Identify frequent words in positive vs negative reviews.\n",
        "- Interactive/3D Visualization: We create an interactive 3D scatter plot of reviews in a reduced feature space (using text embeddings or TF-IDF with dimensionality reduction) to see if reviews cluster by rating."
      ],
      "metadata": {
        "id": "e7dJBWaNhdF8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's look at review lengths to understand how long the reviews typically are."
      ],
      "metadata": {
        "id": "crKOw19ahnDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute review text lengths (number of words per review)\n",
        "review_lengths = df['Text'].astype(str).apply(lambda x: len(x.split()))\n",
        "# Summary statistics\n",
        "print(\"Review text length (words) - mean:\", review_lengths.mean(),\n",
        "      \"| median:\", review_lengths.median(),\n",
        "      \"| max:\", review_lengths.max())\n",
        "\n",
        "# Plot distribution of review lengths\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.histplot(review_lengths, bins=50, color='teal')\n",
        "plt.title(\"Distribution of Review Text Lengths (in words)\")\n",
        "plt.xlabel(\"Number of words in review\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "Or9K1hQhhn06",
        "outputId": "c0f4dc9e-32a4-4862-f6fe-675e64096ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review text length (words) - mean: 79.75595459530102 | median: 57.0 | max: 3432\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also check if longer reviews tend to have higher or lower ratings, by looking at average length per rating:"
      ],
      "metadata": {
        "id": "3PbOJEcVhqDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Average review length by rating\n",
        "avg_len_by_score = df.groupby('Score')['Text'].apply(lambda texts: np.mean([len(str(t).split()) for t in texts]))\n",
        "print(\"Average review length by score:\")\n",
        "for score, avg_len in avg_len_by_score.items():\n",
        "    print(f\"  Score {score}: {avg_len:.1f} words on average\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I181d7hShrZ6",
        "outputId": "b5384cf4-b4fc-4fb7-bc01-722c57565bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average review length by score:\n",
            "  Score 1: 82.7 words on average\n",
            "  Score 2: 90.1 words on average\n",
            "  Score 3: 96.0 words on average\n",
            "  Score 4: 91.9 words on average\n",
            "  Score 5: 73.9 words on average\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's explore the vocabulary. For a quick insight, we'll look at the most common words in 5-star reviews vs 1-star reviews (after basic cleaning) to see how they differ."
      ],
      "metadata": {
        "id": "HYwxxTcahsX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick text normalization for analysis (lowercase and remove basic punctuation for word frequency)\n",
        "def simple_tokenize(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r'[^a-z\\s]', ' ', text)\n",
        "    tokens = text.split()\n",
        "    return tokens\n",
        "\n",
        "# Get tokens for 5-star and 1-star reviews\n",
        "tokens_5 = []\n",
        "tokens_1 = []\n",
        "for score, text in zip(df['Score'], df['Text']):\n",
        "    if score == 5:\n",
        "        tokens_5.extend(simple_tokenize(text))\n",
        "    elif score == 1:\n",
        "        tokens_1.extend(simple_tokenize(text))\n",
        "\n",
        "# Count common tokens in each\n",
        "from collections import Counter\n",
        "common_5 = Counter(tokens_5).most_common(10)\n",
        "common_1 = Counter(tokens_1).most_common(10)\n",
        "print(\"Most common words in 5-star reviews:\", common_5)\n",
        "print(\"Most common words in 1-star reviews:\", common_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_ka8JSOhtla",
        "outputId": "07b7f79f-5f0f-456a-aa30-446acc91930b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common words in 5-star reviews: [('the', 565015), ('i', 536785), ('and', 444679), ('a', 398759), ('it', 350563), ('to', 326016), ('of', 245447), ('is', 242587), ('this', 224745), ('br', 191969)]\n",
            "Most common words in 1-star reviews: [('the', 106148), ('i', 94554), ('and', 60582), ('it', 54163), ('to', 52895), ('a', 52863), ('of', 42881), ('this', 39721), ('is', 33031), ('br', 32615)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see some frequent words. (Note: Many common words could be generic or stopwords, which we will handle in preprocessing later.) Now, for an interactive 3D visualization, let's represent a sample of reviews in a vector space. We'll use TF-IDF to get numerical features and then reduce to 3 dimensions with Truncated SVD (similar to PCA for sparse data). Finally, we'll plot these points in 3D with Plotly, coloring by review score."
      ],
      "metadata": {
        "id": "AH1xLTLZhvWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 3D plot of review vectors reduced via SVD\n",
        "sample_size = 1000  # number of points to sample for visualization\n",
        "df_sample = df.sample(n=sample_size, random_state=SEED) if len(df) > 1000 else df.copy()\n",
        "\n",
        "# Compute TF-IDF vectors for the sample\n",
        "tfidf = TfidfVectorizer(max_features=1000, stop_words='english')  # using English stopwords for vectorization\n",
        "sample_tfidf = tfidf.fit_transform(df_sample['Text'].astype(str))\n",
        "\n",
        "# Dimensionality reduction to 3 components\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "svd = TruncatedSVD(n_components=3, random_state=SEED)\n",
        "sample_3d = svd.fit_transform(sample_tfidf)\n",
        "\n",
        "# Prepare a DataFrame for plotting\n",
        "plot_df = pd.DataFrame(sample_3d, columns=['x','y','z'])\n",
        "plot_df['Score'] = df_sample['Score'].values\n",
        "\n",
        "# 3D scatter plot with Plotly\n",
        "fig = px.scatter_3d(plot_df, x='x', y='y', z='z', color=plot_df['Score'].astype(str),\n",
        "                    title=\"3D Visualization of Review Embeddings by Rating\",\n",
        "                    labels={\"color\": \"Score\"})\n",
        "fig.update_traces(marker=dict(size=5))\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "kQFIIM3Xhw4k",
        "outputId": "aaaed610-8377-4e8a-8ee8-81ed4ea9a6df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"3abc4373-2fff-4012-9a93-2f425df57e56\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3abc4373-2fff-4012-9a93-2f425df57e56\")) {                    Plotly.newPlot(                        \"3abc4373-2fff-4012-9a93-2f425df57e56\",                        [{\"hovertemplate\":\"Score=5\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"5\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"size\":5},\"mode\":\"markers\",\"name\":\"5\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0.18593766785842353,0.04414680964408496,0.09495693191857268,0.17882350911773473,0.10844456234482165,0.33655804061030653,0.15974553740030745,0.23493351393888845,0.34866758057380653,0.17049680990078778,0.18920312106261694,0.10736591865372488,0.2757457133329818,0.18262517906541495,0.09752680482932509,0.31634696805217977,0.36453793380894645,0.4303645286375325,0.029811808695390386,0.2554556748233568,0.31417538945063467,0.1251158097544321,0.12469522914413819,0.18125456329701997,0.1393015532721629,0.21010881280405852,0.15824951292192688,0.23282727925385077,0.12295769537416658,0.32438206495138794,0.11099263739572657,0.17045134411486396,0.15032238572326936,0.2730532397944091,0.1262516142066718,0.10554354470834547,0.18025728166127575,0.15440212148449667,0.1471285048382766,0.12875902587812701,0.14975589428735783,0.33220775382453394,0.18264468531104286,0.27832556018005156,0.3563944549078244,0.23396395366000478,0.10920014697637255,0.04736648717458582,0.27218141463502,0.1255982048327454,0.11497263829702292,0.1444683487769953,0.11566780254624576,0.2438979443006967,0.0847905005683132,0.0931803657427851,0.23487520145733526,0.17739072582331003,0.15053003721157238,0.060453495813753595,0.45270526188416893,0.14934424229986162,0.37584141579847946,0.14662886768216085,0.17970023486321154,0.1526146732512465,0.19584727584325168,0.2116892728768318,0.33468820775201746,0.34379883330487104,0.0907921682193471,0.1149613245456313,0.31105390723303206,0.16750323014051582,0.1787412841796148,0.1721766434342158,0.11383799700029915,0.09937554140447612,0.1431452123885662,0.17136853749778436,0.06923422526132289,0.10919350874076367,0.29031381080785146,0.2535122924907596,0.21036269123770818,0.1648295281732813,0.08757179182219951,0.07289193029652807,0.172622411642501,0.1332252673290439,0.34551388636168434,0.33654632897097336,0.1788850537307692,0.3248254023359078,0.15508689995053335,0.09659982072962935,0.14494325161128668,0.09980788489014694,0.14975389331998293,0.12527464685629094,0.14348834426538193,0.16441174452967208,0.08587084129854629,0.22527367969805243,0.1643195748013207,0.16099061659921973,0.15202890031131178,0.11831175008439519,0.16338059331694296,0.12933072822941205,0.09973461849851001,0.09748889990581838,0.19346712788574813,0.09669748382433968,0.176270937746796,0.04920195505630988,0.36372654414450617,0.06856530081908135,0.11107920761759024,0.14310364331159034,0.19866230180896755,0.11794929576375661,0.18189565898222168,0.18300097723803468,0.07719933810014892,0.48703931311702225,0.14850564471790081,0.08721077614794225,0.3661590864646999,0.1029871780241463,0.14968401648001178,0.13994004078000805,0.12479536786881675,0.04046850821661548,0.24297836137935044,0.09183151980209502,0.06269779138761546,0.43833924125121854,0.12340862036390661,0.3100157512921289,0.32124043211669406,0.21668666786921997,0.5643210383147305,0.14344545083579927,0.26697460160311826,0.16006212379291798,0.20594809120970278,0.11148330853867973,0.22271820871061537,0.3368830158220626,0.3331915553125087,0.17291185071269402,0.0827216695148269,0.16718492452550043,0.10129398190165413,0.08197457539039697,0.09309975603316141,0.08714416305561654,0.23245013434796857,0.1433614440599229,0.23541084012894284,0.1769201036488288,0.10482452273280259,0.19256605082698094,0.40530618202028806,0.26102899960360126,0.10531241287795289,0.08716242020462245,0.323210925914832,0.3080993097481586,0.11211898762972515,0.2096008336401083,0.11847164388388096,0.07612393149893797,0.27837645183467313,0.10334127999508934,0.12563213404596707,0.0994025090632531,0.11212641487224488,0.13448110106714495,0.16526555195892803,0.16101357161088645,0.181842719003134,0.15276632276522403,0.06518047454493447,0.1040981787341663,0.08339097223374528,0.13795821335238553,0.24614006041200462,0.18959681546551854,0.09139023903312105,0.1395119066851414,0.22805747772575607,0.10545366454718942,0.12894312023845825,0.09776322602782905,0.17987226074632248,0.151660508657999,0.12700601470884892,0.23879329929606535,0.19119466406565802,0.19756092787820578,0.12119564090465182,0.08888286169057945,0.19841603599891505,0.14933753718423384,0.31079229814734394,0.0556300912955078,0.19443601853228337,0.1385683500346454,0.04601421487620842,0.09371120826582148,0.1399794110528986,0.1520309425051716,0.2555265253552219,0.15863797723878673,0.16143652937614578,0.15138564893965048,0.3414296177976536,0.1367678636378873,0.12905688061106874,0.13172212607273992,0.1664888266085409,0.09321188477855874,0.2690550594237306,0.5430249735997911,0.16902233806381492,0.20034289926498622,0.2613138591332693,0.10719567452554182,0.16227498597727052,0.2198634622919506,0.18079545031135932,0.10363230392646246,0.13911799620020573,0.18566441313391543,0.3501185720945398,0.4847135919147503,0.09919773721342509,0.1456428967502867,0.1178324586350198,0.20832122511905,0.2680269694044084,0.3864129177742642,0.1882244419806124,0.1419180831250933,0.15436405020547933,0.11060294635193044,0.12430145134021107,0.21317223980211414,0.12176700482900282,0.06468481203409818,0.1506500797437961,0.120043937614837,0.23243985929240488,0.4714311202818201,0.34811604933411133,0.2936897826206276,0.17387603136937796,0.16910102665229648,0.1191063146147616,0.1996659957974615,0.14887362657620296,0.14743238399659148,0.22237825479890927,0.12307677398214979,0.08397472458081393,0.14425088944125353,0.06916726088734307,0.1022306621695545,0.09838029497283948,0.3025058344341235,0.3139634899931057,0.1178550360459919,0.2787631501379829,0.18415378498265675,0.11386135678494963,0.10952434001767601,0.3164309181463228,0.11407654527853756,0.15129334946214473,0.1875915992518782,0.13645019334428812,0.1430771689218474,0.1347662132001634,0.3459062316844679,0.08053009315097502,0.16485845990552117,0.10498401443576907,0.10256936416332481,0.15509464397100742,0.21009082668754847,0.1577941971632627,0.15566542170395212,0.12303823613547059,0.17008909850236728,0.05286290282929493,0.11139294656823899,0.15666676234826457,0.16697131274403296,0.14215719154782475,0.10200138833436788,0.18490402502492748,0.18556862998013066,0.2762142623207732,0.06961601282355792,0.16690113349411606,0.21915841167366915,0.2227575931964688,0.29785576019026355,0.3117421919513944,0.2677039080580642,0.14555207853827495,0.08443291308989513,0.36129705644763904,0.13098448286465952,0.15905640313968905,0.22976114296023864,0.09714318181750395,0.12497502624663846,0.1907511020127839,0.10461977638414839,0.13719350592245574,0.13867536162158386,0.12909856362542796,0.13566471593504964,0.13297418786383391,0.08354117990350894,0.1477810807977271,0.13244477612664698,0.10755581083084766,0.20233291615438154,0.11104331609845487,0.1481808989728817,0.14023635542994833,0.1614243050073978,0.11930955608553313,0.2637447004120527,0.08028207163733525,0.11556616265462229,0.09055982622127173,0.4238898804685093,0.17985104876928287,0.23463888801444682,0.1018383117021049,0.11490138364605872,0.5072890103594779,0.292022137375283,0.130127741111995,0.0769290602239631,0.14796813847600845,0.1312038693325046,0.14065545637230598,0.13844969716247246,0.181356256248503,0.13503113902344344,0.12219360028119296,0.09718514465131482,0.17141867967467955,0.13912757230323056,0.1667000760743516,0.11692954871443517,0.2554429144546857,0.16784428597823517,0.12012906114671268,0.1093293952452325,0.11217107084046127,0.16522540587350232,0.13835836747226388,0.1768038328491863,0.0930994581543821,0.399309260045419,0.11823737446383417,0.1638225656647419,0.050457111780339535,0.21993133846565763,0.06960677843481355,0.10257502970976219,0.12088034065829613,0.12846471614810148,0.10795409548508529,0.1618315846502723,0.07935565428415033,0.0867297451718958,0.11506865680815657,0.06984647047047486,0.2654437448774252,0.11177885666164268,0.13471599432827602,0.0853552030560113,0.14341428751619142,0.07330517262919518,0.08686836428034457,0.11055068465748391,0.1299898843372304,0.41711507401591785,0.13596614708712634,0.1350828141996913,0.09874306223487626,0.41912075581042485,0.08241447802731006,0.08678674577239548,0.12902300820260346,0.1775936609994758,0.10828251024045589,0.1314334980045773,0.13449312960783677,0.08793408402621337,0.24907842512175815,0.04757568095348511,0.24884195228077582,0.26365126265622424,0.13144449782318468,0.2577684541071631,0.14693092846352118,0.1484319606694113,0.19777663668865564,0.11047086127332255,0.1924801022984743,0.1354741839456666,0.14302949143810403,0.1300480409847754,0.17400386345283889,0.07186673895664643,0.08454154440103873,0.1895755588909699,0.1730033360194459,0.12214425343921742,0.10717820509496448,0.14211255686801325,0.09331023607271083,0.10540749160595873,0.11221765563474972,0.1425350801722269,0.11592831679303905,0.1446744023818058,0.24809847114806774,0.16299555598902918,0.16966000583732374,0.0684871142000899,0.29739347024703033,0.09554367743901351,0.1345273141455025,0.23553277423538133,0.05226794959961071,0.20379389895198344,0.1880321288327097,0.13907468945742252,0.4120527517179315,0.17901182792126802,0.34539604593944356,0.1667291640542006,0.4454642035775491,0.3582392774790941,0.2035060355593113,0.15354699958785403,0.1338919441321687,0.1623974092100285,0.10035907423546271,0.12963734231349477,0.3934252902056646,0.19335511478426368,0.07627602238933277,0.13530267795544165,0.1456053141108442,0.15491039675001175,0.16333805111612457,0.13109742671958052,0.09557634600078785,0.11941873397128656,0.10758809314617714,0.3003143996841037,0.1909777642972404,0.0890506105400152,0.11399841494125795,0.14817891391445343,0.06204464130520605,0.11514180676465458,0.1373639264557172,0.09010860248843294,0.14313067286373227,0.10363969385737584,0.3334268205540439,0.18981546144458972,0.22241572312619548,0.12217238901961028,0.17056464683883313,0.18608987020072387,0.1556409351162325,0.21130173621286666,0.06762765823896733,0.15032701454569503,0.17225974296540902,0.10053995340458857,0.18467641407415128,0.28179753558484233,0.030180011269959967,0.0783637967802241,0.20156507856234357,0.4158951421674804,0.07802095875330611,0.07742224658140086,0.0963777249317332,0.11823205627954668,0.19700198655836898,0.10400885293771284,0.45727753653989855,0.3106380220890704,0.20566169811403415,0.11733343625513609,0.16682525359922423,0.35698797117412995,0.31075492125875176,0.12554058339862037,0.17442665022218598,0.2266199605359067,0.23905982531580927,0.13302869155769317,0.145436971501842,0.5654606633067483,0.10161633181678509,0.0811791096209914,0.16039391957156646,0.16896563908327145,0.1468794820284535,0.09702588959097806,0.13447893437264438,0.25453882831543445,0.15029030958999973,0.3991384030712071,0.23898561025258888,0.14856846001016144,0.17857564587162944,0.17921011238219148,0.08276096032016585,0.08993782069958527,0.07048949255611918,0.14892703327381882,0.27638143826538636,0.1960711856502228,0.17052457484172143,0.12986474900554695,0.17024487296743968,0.11633164099960655,0.2573872658330699,0.44453898457989893,0.3112785326132904,0.16951144090922887,0.30433623951028543,0.19972413551842969,0.5755241237310381,0.11476007062901808,0.2340975574162704,0.12191257123659352,0.17110424671551885,0.32922782400902684,0.10469930290734153,0.3208743056218011,0.30565849973090686,0.11592255738362964,0.1664711541289011,0.11642595773324495,0.10706789049127131,0.0883946416525955,0.13906253979502295,0.14893560187579513,0.2317192128390574,0.2988374646581142,0.1926920662572551,0.15278883269203336,0.3159177269899882,0.24868104532171323,0.36478461528213224,0.16490632613524758,0.08911092422799344,0.48650072776943587,0.2798516919008498,0.40121380041998855,0.16755359670605793,0.11746552863380047,0.17777171079740087,0.15793851866407452,0.3980006340714357,0.12284274698635751,0.2059900795875376,0.24347017924483605,0.10850644789716737,0.19152877340163094,0.3163540470059792,0.19819247903497691,0.19682743832762384,0.2636033918739185,0.2574490517375954,0.13969133875878956,0.28526366088633115,0.2620533877453277,0.13745244434061438,0.20965399497400872,0.12390588285356699,0.4035377780141098,0.12312094839978761,0.11570921202227229,0.4673779739369523,0.21199887192607914,0.1957564481142219,0.15531783199185217,0.43674507552840847,0.12659890038778202,0.15158457334591371,0.21628783746013824,0.15491004428726077,0.16846060964143184,0.20822569762780596,0.36553209906704953,0.26016016953865395,0.3234662795381171,0.1291097563129756,0.047032524666207144,0.15096159729778724,0.3237457209760956,0.14746706505932622,0.17344691248531832,0.16092222991687993,0.6386099654227025,0.2443401464297103,0.25198770765136747,0.15303469264691982,0.19112371455192906,0.30841646764168007,0.08740706081797654,0.16194499682254695,0.14078903915966068,0.1775560198301881,0.2735328143367738,0.09636653267889758],\"y\":[-0.1631574232361093,-0.011914261788695231,-0.03550971940464108,-0.09687185394084344,-0.03845354383345165,0.12883875257336364,-0.05912465509907535,-0.0044209144949669925,0.13046681269761298,-0.08978283380394007,-0.24814323835161256,-0.03835632692179914,0.2834705922538604,-0.09574087684637454,-0.12574740208886637,0.13480107584904147,0.2645085889097686,0.052021463541178835,-0.0033206014279521284,-0.009831336292748611,-0.21598762891859313,-0.04659534143926203,-0.06265144252518712,-0.07620759467288916,-0.06403624337937247,-0.02680549763137674,-0.04872304160910374,-0.20891580731720769,-0.047627054027880734,-0.10396725768316328,-0.06315379942725068,-0.11167906066255479,-0.05099188572277508,-0.050844438395750695,-0.047552930183889355,-0.042368415578542824,-0.06946465863880946,-0.077015556214469,-0.06846353452614885,-0.09134829711358716,-0.09167134683534812,-0.10332242205949582,-0.07376902248206782,0.18803909825463871,0.1288749115403713,0.08730928501994262,-0.06360084146464283,-0.00874430684497144,0.10768687359570978,-0.07938924255377428,-0.012702010649295811,-0.08354272052212386,-0.051754119591994045,0.08054199100820945,-0.021513847300533073,-0.050850182269902795,0.14736102742001203,0.11595319785262523,-0.065891241006056,-0.03221234486790721,-0.1636392313010461,-0.023755312635331486,0.1582605251787822,-0.08181671470723621,-0.11143245370902091,-0.050040106903096924,-0.2871611457777448,0.024080269763880544,0.17148945253408687,-0.04688253459240953,-0.02782097117741495,-0.066723329268483,0.20904856505687966,-0.17221266011354028,-0.2057601650675329,-0.0697630998161093,-0.06989489828996549,-0.048198809380212704,-0.0465822670849921,-0.07649234047672246,-0.012521295205303675,-0.024754446677063568,0.16474712577177178,0.05310512935985862,0.11249248418715499,-0.042660760328226306,-0.03411052714272911,-0.010827457331716889,-0.2149731001202447,-0.03331294092592003,0.20599470885285104,-0.27422873152360994,-0.0696507726386641,0.1654924486183142,-0.05735665164338367,-0.03407562436916024,-0.1270164423990303,-0.05274114434195907,-0.06101309372231341,-0.059314160244684326,-0.029333113115360205,-0.05256450098102239,-0.040180118743041525,-0.21688442956782228,-0.13477076031219618,-0.07526888550582633,-0.032544452414616495,-0.0517444036708516,-0.07849621388976484,0.006307701716189538,-0.05881176254598932,-0.038473460583136304,-0.09851103257264324,-0.06927850035082787,-0.14721286888256752,-0.013474525215679349,0.1415704055996499,-0.0309064151781809,-0.010537713082116986,-0.08574804011116585,-0.23141575389163463,-0.04904610484607481,-0.07197065134266001,-0.06365436708179047,-0.031864964572850714,0.3922558872460134,-0.12730281921417708,-0.04337477751858236,0.24729753215809727,-0.04182510461650857,-0.0886857231802257,-0.08191310547794553,-0.04469624378589049,-0.019627051379036718,0.015575759520533458,-0.041098207233816415,-0.011943855192796757,0.260907055648089,-0.08657190755263815,-0.4342733105219535,0.179198619702893,-0.15137652667736987,0.2294597076041864,-0.06692356018720198,0.07895911247221357,-0.07803082054194026,-0.016674558132592054,-0.05109602898800756,0.021988619244709056,0.04244831793469362,-0.056621674082624834,-0.1009946426657591,-0.04088292377409264,-0.08529896298268343,-0.037948889446544946,-0.022388508292304606,-0.04382497815337648,-0.06911537662729442,0.10574694086255175,-0.08924575429726535,-0.04274140835540152,0.06320240034612758,-0.04581991184657479,-0.12380768649919076,0.09394147953419832,-0.20779172324412792,-0.043852217325183455,-0.02520368453369354,0.12339939057876752,0.07911176495833129,-0.07791201800999262,0.06152889325311863,-0.04906740809598707,-0.03375326718750156,0.045131731789443595,-0.07827763853645249,-0.08207871348466039,-0.04510629491057066,-0.07633016926111547,-0.05421133598585704,-0.02893097163045305,-0.10309918186685045,-0.22572082174454106,-0.056923092016226855,-0.028643718051216384,-0.047841358254953545,-0.03230753068725243,-0.14705441522725193,0.030716924715841823,-0.1830849412642009,-0.0646840047881835,-0.07719042915031833,0.07713116888861891,-0.05547711574132629,-0.0650970146523975,-0.028089434198656435,-0.08907021307505951,0.001262531143977528,-0.10945518611736252,0.194255701088533,-0.08451301614425293,-0.11572030571950642,-0.1236237601665153,-0.03385902939142908,-0.044176624080982864,-0.07699960283784826,-0.06369383942565263,-0.02200777784664603,-0.20446919744264466,-0.08635319371207338,-0.022898923085755196,-0.058624643589738755,-0.09025191464942106,0.012930314047677418,-0.39992021314268306,-0.12973748406117439,-0.08766911709405063,-0.03558849413332987,-0.2711854631580564,-0.04832197359268799,-0.03684601484000473,-0.04001840155255582,-0.054296498835933335,-0.06029697384697875,0.08392223043974276,0.2038365767927292,-0.048765614383724114,-0.10385018216318834,-0.3741051701474708,-0.04779692439936764,-0.06913758461398557,-0.1169953591904433,-0.09100645343086466,-0.018996037605688264,-0.04408188673077086,-0.1002822460035633,-0.24340962873663502,0.38379901524154897,-0.013757935940106651,-0.047175567022068286,-0.038176431843781486,0.08175259239049953,0.09845200538886172,0.11762987796921924,0.03926887876035908,-0.046680295638304885,-0.18908284101786113,-0.05488602883840829,-0.055184262298774246,-0.21517722904385755,-0.057478967959182926,0.0044138967592591075,-0.06146716639114945,-0.09678352182145841,-0.23190825314753538,0.2933180121500389,0.2897401683508383,0.0550456245743505,-0.3115038076285154,-0.07133814135044904,-0.054230089998790365,-0.22821880069622394,-0.06457506221164798,-0.06638048245224056,0.15989664760911831,-0.014361421083228723,-0.045063071541371444,-0.0691372079966826,-0.031190930507685906,-0.049460051313104894,-0.04237632883343532,0.05820385232525621,0.14266281265491507,-0.030419480440912087,-0.2513754854573008,0.020072792264146804,-0.06520722047316117,-0.047513502806745135,0.08048555092543391,-0.06100371470800308,-0.0958587105186362,-0.18109262787218317,-0.07398356752388635,-0.042116559822985525,-0.03564245102334332,0.08848370040875173,-0.06990691135741703,-0.0618877475948832,-0.003632709869234474,-0.03308735819729486,-0.08514683493049331,-0.17025931284898763,-0.08581877906015373,-0.060899584083182266,-0.058249999949299594,-0.07110034366250673,-0.005136226398029036,-0.06969983621221622,-0.0689759684940079,-0.1646098314924096,-0.07844030844904493,-0.04921743851244269,-0.10321093250496241,-0.18726320027177765,-0.05742119219955778,-0.02869666853419571,-0.09686960523211743,-0.11273826953477986,-0.19411085032948816,-0.043872610710613574,0.12850429798588445,-0.2677516597327866,-0.04059109224447342,-0.019616685807441456,0.21553696164345135,-0.051774201171277734,-0.07143679520741561,-0.35920706237338607,-0.022988710033136534,-0.13263084823311708,-0.05270678646144271,-0.024803263520962925,-0.05691152795594474,-0.09792906068978288,0.04736939569192299,-0.15994012515018893,-0.013320850552235006,-0.01457881968589722,-0.11315881009392442,-0.13469435152091866,-0.050767464335585516,-0.09137011264065949,-0.020511418048068226,-0.059102125828512694,-0.09550100431703029,-0.046362474067712836,-0.053769695080178904,0.018844667261136535,-0.04848112977979052,0.004397410423182521,-0.04016642530154649,0.4435145648886929,-0.009144228619037298,0.057707187103049895,-0.04203964783794536,-0.024201138285690312,0.2956480744802037,0.12510979268753766,-0.03378971118850074,-0.05643228795348494,-0.08712291103393378,-0.0828382299812553,-0.06340520147754854,-0.06418248821097682,-0.10794760019689063,-0.10339609018015172,-0.06006384960378661,-0.04888597107719042,-0.09673831296894021,-0.12166057290441307,-0.10622418967125974,-0.11389867175633016,0.21924149597146042,-0.057416020012344866,-0.04087281563411744,-0.048811618998194424,-0.03018436686013232,-0.05497978696363874,-0.02846788720185422,-0.06894500545920501,-0.04040856575080485,0.2613465069618371,-0.1496095810091484,-0.09288041416342074,-0.01816587118472866,-0.2072461037824881,-0.025824745949273788,-0.049777405736689026,-0.040221184184687626,-0.04848212893606812,-0.05751235490287775,-0.1014007173705647,-0.019947143171151552,-0.039989088670176746,-0.05151247337711854,-0.01887962418467914,-0.37148695341784144,-0.08224517858525984,-0.08695818691112472,-0.022156809087420435,-0.024010872038344407,-0.04880816911804788,-0.04947809533553335,-0.04060966235854618,-0.07194472025862288,-0.03650860540111652,-0.04258233044062482,-0.05539762668452238,-0.058011370337514696,0.2503675416047752,-0.023933875233879586,-0.03680596976587548,-0.12642678298852889,-0.06453891049707862,-0.03914737810549492,-0.05071699910849864,-0.018814357842935354,-0.029458613999064506,-0.3548519838390286,-0.03344467662772849,-0.3000340909482803,-0.023684597294693188,-0.2343252540822695,-0.22374487454252287,-0.07923872953409655,-0.04396105690861043,0.09826621905555462,-0.04765403725264817,0.08344488771335533,-0.07370761321326574,-0.06347999260882038,-0.05486343973623673,-0.17715200419828728,-0.12406794834714574,-0.034544615324060945,0.07680311904937723,0.02515735158546141,-0.0722632950510492,-0.04106753639573949,-0.07635851274137008,-0.023025323568353795,-0.03402379674176682,-0.018294598827459978,-0.044895971765414336,-0.08785343006872068,-0.05392442085315665,-0.35610729011690856,-0.06892551099058672,-0.07327083185881798,-0.024195776906225798,-0.20875398655471378,-0.0688867997197955,-0.051840859415332896,-0.14784314472300245,-0.007869929529270375,-0.09203088253871859,-0.10138529123823789,-0.0685930451088276,-0.12866022224668983,-0.16868026031721184,-0.05050261317807689,-0.030249119235217406,-0.0754972859551241,0.28324673366965775,-0.2168423602221035,-0.05811468823081465,-0.05563554065606661,-0.18547079110767878,-0.05601305319703553,-0.05989134441609548,0.16421043314452918,-0.19479748607665895,-0.04425604003484335,-0.06028533572145868,-0.09869981709834631,-0.0732332035344728,-0.06247536310598996,-0.0709547117870561,-0.07393911965576667,-0.04733023430710025,-0.13270596594568426,0.18155897580322347,-0.23301079823905288,-0.0310007980524471,-0.04378778896204813,-0.0785999753250481,-0.03665299702024486,-0.03125365811764503,-0.07785047305582955,-0.025400745591581605,-0.14058318714820275,-0.039780395414980615,0.0372411658469263,-0.0916042516805034,-0.18140329304640496,-0.11439936794350722,-0.12468526302284455,-0.27243484185693684,-0.17546860122222924,-0.10725539228840873,-0.03030688421661941,-0.1883158261448091,-0.17944190250399755,-0.008089861308134584,0.032221998903986984,0.19924643971449388,-0.011476953619130105,-0.05480540696254595,-0.03077099211819566,0.2312927332164361,-0.06197497250503005,-0.023835721525300054,-0.03159057611754496,-0.07823431684636037,-0.10799538424976209,-0.025056857388812904,0.38596827683398155,0.1279720866183176,0.09754891916245331,-0.07583746753428737,-0.1044514296196563,-0.29443457740918677,-0.19023200547858848,-0.0612600882930888,-0.0759854978397897,-0.23956006903267288,0.07493024384319352,-0.13143680842864758,-0.12156219675870925,0.31857207773372115,-0.032350511518553816,-0.03900680918787532,-0.18082332132219045,-0.16572860393281902,-0.07445855103446443,-0.039496615141077746,-0.04653803016784826,0.08475313913759001,-0.06365895096173811,0.23823375327357477,-0.09580230190018983,-0.11518870968310004,-0.06833087274576767,-0.090932227428189,-0.018344845297904068,-0.060764366389064205,-0.05723998132401316,-0.14433750617503022,0.1725906607154955,0.08694028589286318,-0.08844403443614483,-0.050619244821617504,-0.07421659382249138,-0.07610409357616486,-0.025483116675663213,0.2660638251492905,0.03022447594758442,-0.11932002036912064,0.08371988552203845,0.10420769541533938,0.08690834013035303,-0.18466700007605175,0.07336656637833461,-0.11460261784972874,-0.07454944366223452,0.31599488277324717,-0.09787769025405366,0.27952220960655766,0.14636852379982487,-0.0558318627929294,-0.08066733269508768,-0.06924506461424823,-0.043885891714558256,-0.061399877109540923,-0.10639821215015237,-0.08677970400485116,-0.15482036493998613,0.1474545702093634,-0.2373626499079849,-0.17505592594944563,0.1627617483575574,0.07494932952457407,-0.014323065654658781,-0.09570785609031385,-0.0338197848360574,0.030152396536940015,0.08190594007907591,0.16382825066783846,-0.07795046130006458,-0.03941061951630034,-0.18307691422079547,-0.06025928562860537,-0.20806169352640946,-0.057758470305994486,-0.302691429430461,-0.24624153438947527,-0.06314649049673213,-0.11338083111855958,0.005971169463091961,-0.06280075824568317,-0.09224979802691745,0.06425414049655044,0.189416757988481,-0.1754824384814997,0.07747485065398083,-0.16257470048355746,-0.03847726428810225,0.02808134084842887,-0.0770166715545447,-0.04855954951039108,-0.041299363033955,-0.09674721535914377,0.23502297202286734,0.03927527058744432,-0.09014883063353395,-0.06464703659920822,0.24002043946111268,-0.08204113399020278,-0.05275842105681445,0.0851459321870892,-0.08472499945428713,-0.0808562685809284,0.04022628527836089,0.14150456625044255,-0.3078384860943102,-0.2904650032604762,-0.04148873821336716,-0.007913203038194651,-0.06317258255195678,0.18680446369791603,-0.06834333509127224,-0.0753601899976946,-0.06424165820823577,0.35114724298805855,0.08882185224944746,-0.15508448744396594,-0.07609147583229904,-0.11963916145026902,-0.059767306246434684,-0.025109979206781353,-0.1723906034191614,-0.06653450031833155,-0.08507447775947483,0.1789911124405133,-0.03480048079985468],\"z\":[-0.16562025621381515,-0.02388368971356225,-0.08048342070751095,-0.07416883413638378,-0.06666195694480481,-0.03168839465581025,-0.10891866542034262,-0.08892929421888299,0.006262197094697704,-0.06300233683572183,-0.14233714813394105,-0.04485820472145202,0.08734728246127742,-0.0982610817294046,0.16038285219152887,0.010447934595511375,0.07603827369656796,-0.005626007171061185,-0.009766464080991874,-0.09465184068737821,0.5050452924609798,-0.05625848779172908,-0.07802178560666645,-0.09822953232408785,-0.1056021835048622,-0.05125352418002304,-0.09562408304789653,-0.17993722835204168,-0.07033439046266576,-0.11344469529938253,-0.024809843083384325,-0.15124974336623842,-0.06966545363023564,-0.008708141516781261,-0.07169307955173623,-0.014900543117565706,-0.07147555480374856,-0.06910463862846691,-0.05039391402868231,-0.1027228977249905,-0.06825376004048607,-0.11884559965360986,-0.10875842412852117,0.05428055195615892,-0.002959764040235239,-0.034296046173224355,-0.027353300762287685,-0.013315602716993712,-0.052523844932344466,-0.03109120162882919,-0.06759328503454397,-0.03567155228910936,-0.059727482930034353,0.019800748921951827,-0.05836690533249079,-0.06272380899408704,0.030236636823270716,0.02945968398806284,-0.08401952224810377,-0.04807210391115245,0.4533509070023222,-0.11390419253651625,-0.010293210676698155,-0.08960890638305286,-0.07546535575101294,-0.08867985274607246,0.29703037870766885,-0.11153293921658962,0.01110591407385372,-0.07151551432884858,-0.060196483156335044,-0.06874067783956984,0.013785656757393832,0.15561825341925944,-0.15899986216881476,-0.11344881644437922,-0.061889399966269396,-0.04538767809539824,-0.06971043729012756,-0.08300327704989849,-0.038287796881804156,-0.09762472415927849,0.0005810826754885999,-0.06508801620287746,0.016106560886105327,-0.08963147857134611,-0.03956832206887728,-0.053416294430321073,0.24092795672056624,-0.07400011623485084,0.04323312505246877,0.4843896738447153,-0.10058031123953928,0.021567941075642846,-0.07320373004557232,-0.07505769774489206,-0.12177631965529058,-0.05674494946615559,-0.08882311460896047,-0.10294701298801126,-0.0591787781168425,-0.07471464240338523,-0.05287113111848328,-0.1703500072639145,-0.12694351194883802,-0.08837757717739073,-0.09477622230625095,-0.05273390486431102,-0.1305208639773579,-0.131902484088149,-0.0842724262243124,-0.03904684684992036,-0.12109622633692912,-0.07321479175259722,-0.10057814892581896,-0.022412610330386967,-0.09616989099507767,-0.03128788485500898,-0.06860570498197309,-0.09062200268539866,0.20420243020539977,-0.07597845930889992,-0.06014108175503045,-0.14370287104624901,-0.03964197356357921,0.10940920797014599,-0.1274917838828587,-0.047439239340141555,0.057858276122573805,-0.03138767362100091,-0.09634333897207797,-0.08542933500704304,-0.049947915019715364,-0.027684676019670167,-0.041935141755457254,-0.06086782440612954,-0.035233713592817024,0.05785565152827098,-0.042921489848709235,0.34906124392616183,-0.051009592360073956,0.008621342896286778,0.005442350607259397,-0.06907298459670157,-0.02535505603290933,-0.10540344544577265,-0.0705760378051088,-0.07790888035346266,-0.049906833920179174,-0.10278658615410052,-0.06499776684614429,-0.044026625913900344,-0.03545925700349723,-0.06295055186262792,-0.05173835822845752,-0.05406648887601893,-0.03131765579561652,-0.06963461529766969,0.008770055618621408,-0.0735106041027665,-0.10548207308518283,-0.0371787265879286,-0.05661404781055471,-0.13147101693287913,0.005973232612830847,0.38772155667443453,-0.06956393607612654,-0.06632313868429796,-0.00044503580507943377,0.0635071692696383,-0.06430068693611449,-0.03681496919139936,-0.03582425559237944,-0.034397439473438256,-0.010520186976290995,-0.10451132193961896,-0.07288649944149941,-0.08090904416217055,-0.0005888404041786913,-0.09197588845581121,-0.10452926021659457,-0.11673655422207216,0.2607758804689083,-0.08556697390981705,-0.035197419467257976,-0.07765996959607903,-0.050363746047791695,-0.11510198434179203,-0.06422767371243747,-0.17015618474686262,-0.07384196802170964,-0.06867507220685387,-0.026369682402928345,-0.005049879784155913,-0.0585284132939001,-0.06018105948997043,-0.1512774222823964,-0.0415201890124918,-0.01179319235116297,0.03500858282964934,-0.1324042179233328,-0.01408130558888875,-0.04970947303313376,-0.06767469574259452,-0.05493020209891105,-0.07099366894236442,0.24640281828824256,-0.03137935856625765,0.08333986733285577,-0.07414381052040354,-0.03474821015217805,-0.07115210966115072,-0.09459253001810397,-0.03345249359090153,0.5812869918231406,-0.095025492655871,-0.08741392855429062,-0.11508112733870655,0.5844707054060087,-0.08276615546072934,-0.09656424141910687,-0.09778142951597725,-0.10814839209935455,0.0004525082014023141,-0.08542604423619156,0.049022173497705025,-0.07020357256074866,-0.12128642655636757,0.34865342392188703,-0.07608868964040096,-0.09454127067685796,-0.11039198323870941,-0.09302666484645057,-0.05749967945612788,-0.08198736668536892,-0.12358966724017137,0.4843092773175247,0.13432781669037328,-0.038706422887259125,-0.04940125795844429,-0.08425823749170837,-0.01625347640930019,-0.016130733427519688,0.008807791874022171,-0.054080016117260384,-0.07836042266425598,-0.04148019889387927,-0.08013872348965953,-0.04900678394532889,-0.14402593837402078,-0.06833697814501602,-0.03352582634568383,-0.07198725537447952,-0.04065446435524002,0.04549406344854434,0.06171591836656472,0.10684572979501457,-0.04711944821686197,0.4060435702646607,-0.10010876781197871,-0.07499807911575543,-0.18467352429104128,-0.09388918388167546,-0.10543526378026577,0.044995183581548776,-0.058346718429203845,-0.06919639925034471,-0.07995304976547084,0.0035586143928021123,-0.0653046112363672,-0.09316192046384021,-0.06029277951098766,-0.004187166373171722,-0.08244284744547141,0.008448843219739727,-0.057262061097453285,-0.09972613438167482,-0.05244564246651125,-0.03626133960755159,-0.07925608341553923,-0.10913059807276887,-0.06030037592191866,-0.07464958246198146,-0.08318150300762657,-0.10331301938925347,-0.019656289540110342,-0.054962133013903236,-0.12513684155619711,-0.0778731363849142,-0.024402153226588764,-0.1170730057093122,-0.14326215615567095,-0.07596435732047564,-0.07640677706666368,-0.06920641132829215,-0.10613199041094028,-0.018712531680838973,-0.050729549814884596,-0.08473309973704928,0.11079850103683646,-0.051977970190156805,-0.04108180949605556,-0.09778877410104816,0.08237918894458669,-0.11138027095704627,-0.025167306347964345,-0.09698945944904748,-0.14067677607571805,-0.13690914342549462,-0.10544719934600079,-0.04828579834330541,-0.16039393902536286,-0.09242595230770298,-0.0685765801647812,0.018634509223921385,-0.08417020446839357,-0.08603903030946962,0.38903385872947543,-0.05067211762383213,0.09456347933889232,-0.13138641675266016,-0.0566316551387802,-0.03358145745000316,-0.07570040965476169,-0.016621706264130138,0.09757768176000903,-0.1124423310314273,-0.059502142095529315,-0.04451298580331883,-0.11765049444834629,-0.05975896609962049,-0.1352189933533486,-0.08877614248513208,-0.07983621009087197,-0.024106355570340344,-0.12815052712547653,-0.07513227882685197,-0.07278306124867304,-0.05211533854024044,-0.10815785299216713,-0.05064759539310323,0.14432536457747627,-0.04725288201101872,-0.0201792010827139,-0.05671635352003617,-0.05090426118530665,0.05796639365419453,-0.021297121504979977,-0.07531859188259177,-0.06815361313586302,-0.09140288059934888,-0.06305213136262584,-0.10930905413274178,-0.08253511378742535,-0.09999077513352962,-0.13551930447896982,-0.04115544680851246,-0.04648390304999944,-0.09942461110022875,-0.08379455932655115,-0.1101558694916631,-0.10741345333381155,0.060691475436147196,-0.0821845416577465,-0.06225568593897483,-0.02306507656059638,-0.05795535154094689,-0.09850957516942878,-0.12215546932257858,-0.11294458166496849,-0.08297144022654986,0.052251531414941106,-0.07381818889640437,-0.09603610116640415,-0.032889124938114724,-0.10685138240535988,-0.02728463510197889,-0.058705059592824245,-0.0746715667190552,-0.1062229382644134,-0.06244270634665472,-0.10776493278821543,-0.08260901678392196,-0.04875211177768561,-0.07817089153192541,-0.03252211376709499,0.3693605337257426,-0.06636324322303153,-0.03349172002345408,-0.04651941145604971,-0.08741581351783138,0.007488793683969363,-0.08689065454792662,-0.0807626912723312,-0.052565395271871436,0.4970331322826111,-0.09429629075001361,-0.08005967319532573,-0.018437272059129615,0.03575548785285477,-0.03535507489703771,-0.038430135742877077,-0.07732171217474158,-0.12360620537778953,-0.022947359695741434,-0.08541049868003252,-0.10353020612793196,-0.05486853178630586,0.4229396321540722,-0.0024527127744894007,0.2970436583012299,0.05673353764426028,0.3359093166862519,-0.11767434830535438,-0.08965167570552292,-0.08483247022892125,0.00013631875439403906,-0.08244260655791269,-0.025221547429666036,-0.10648735271412992,-0.08557699230191124,-0.07833015040458924,-0.15042936655626424,0.18846950871898094,-0.044500720940268045,0.07275122644109204,-0.044033038674926965,-0.10612082318804926,-0.07322464971915793,-0.0552270925918737,-0.05025512904913045,-0.044853059955542354,-0.0829355220378454,-0.07983778644179261,-0.0873768781811606,-0.050693339356028606,0.45780274789794556,-0.15157101808205442,-0.11237953262872413,-0.053277486901217086,-0.1617900584442157,-0.059775378968720046,-0.08005187810803858,-0.1357824175219895,-0.02408262171992611,-0.1333379743424261,-0.11731172639783721,-0.08031255499329651,-0.12096792595067529,0.11993318666004268,0.03049070337506843,-0.0403132447647794,0.33846451662429883,0.04700786418660693,0.05309410015786993,-0.07519566955581487,-0.11117092223416042,0.13406523565233802,-0.0417074897049544,-0.09356473875460675,0.1265425890455364,-0.1409361471152378,-0.04582849324881353,-0.08164821244919725,-0.10363842140915035,-0.09646796410381298,-0.1027888639328049,-0.10951898467670801,-0.06534912460020341,-0.044448565954408485,0.13331160117606852,-0.029647361068866243,0.2626593624979052,-0.053665511942694186,-0.06844964818761763,-0.09268921347190288,-0.03232831708761106,-0.09216185681866097,-0.12467720925650322,-0.04857550120408965,-0.0985014338936742,-0.045076639259629174,-0.08306159196949432,-0.0940578207621424,-0.0923901964504647,-0.05255386904326805,-0.13253390139940419,0.15082112562476668,0.14654104905414944,-0.07454308807998068,-0.0390846127496612,0.09054580478868371,-0.11280841533747041,-0.07919386864494786,-0.06059214538633678,0.039126577756643695,-0.014629488808461537,-0.05300722494658995,-0.13701426131684774,0.0631556770759922,-0.06403565408128,-0.036335399148602426,-0.06003909973377398,-0.08400678588954219,-0.07881625301705486,-0.025923084758002066,0.11230995696299712,-0.0028286996830053463,0.029736105589565586,-0.08037580336991607,-0.038113662994660104,0.5175810040855934,0.2925665854965661,-0.05521917669219824,-0.09372519246635563,0.14029975929231983,0.030909521716218684,0.1204979388396373,-0.10318062275684933,0.058058702042178445,-0.06063678382079,-0.05767285764781272,0.11199494156135556,-0.09871833022567864,-0.06886339447443858,-0.048249303552938834,-0.08311017128520518,-0.06001698785404758,-0.08439141850761968,-0.0009848777471062773,-0.11512329439055508,-0.12886284320977653,-0.10149385401509535,-0.09474265586317858,-0.043699797050185944,-0.07191744862989834,-0.06438515120100755,0.11869190558872271,0.023332240256297265,0.0014697067081149537,-0.11266720228092454,-0.053487076145552384,-0.1143364761523631,-0.08921062049255579,-0.08118318416903493,0.03187725642954215,-0.08478711579253191,-0.09295090416451213,-0.01864968522762479,-0.001573914573825906,0.3636762480310901,0.23508388645133782,-0.01670018625342805,0.12011432593371857,-0.10064585596781925,0.0950091773153786,0.003955654927878527,0.10393810882856014,0.01904265339272413,-0.043192677380173475,-0.0769574916929775,-0.0540640401794414,-0.06103210099735991,-0.0714181715030115,-0.08895586317883573,-0.08065398683947468,0.014376716703866544,-0.04344239742163209,0.2303295487448802,0.1359877436646374,-0.05995625040602796,-0.017276512822776577,-0.029191290910790188,-0.07464008351298325,-0.057890875129231384,0.5073865277142335,-0.03796893869330374,-0.014832396610105176,-0.08995120481152147,-0.07928962237410392,0.17207268454474853,-0.08429824727047698,0.4981203212158664,-0.05322414068770722,0.37125756115936875,-0.15440208760197266,-0.12060282266748876,-0.13707742592942113,-0.06888268891139901,-0.11047945705801107,-0.10696767083992695,-0.05983546055209805,0.05797832505517888,0.15900054169318037,-0.03654601280805966,-0.15526008629086804,-0.09081676878407856,0.017091753411217724,0.014608567535098985,0.5503867781396887,-0.026232498551397643,-0.09927652619971813,0.016886970517220597,-0.06713700374481796,-0.06298494000700036,-0.08477109146056787,0.021679431694500772,-0.06689189005191813,-0.10568352510645934,-0.008616562054222104,-0.09188077070554186,-0.04662475698620687,-0.06020333763513626,-0.00877199598679611,-0.24817284882060592,0.5889713921548225,-0.06074195958703538,-0.02699975611970931,-0.07516915877069605,0.0432567863194715,-0.09121520568998974,-0.09967432034022518,-0.08573941156790446,0.10267556062642973,-0.0922227601559343,-0.1984410837090705,-0.10649110115004838,-0.1493662345713863,-0.08516302680573754,-0.05254583905436823,-0.13766478208278982,-0.11478385185826184,-0.08545369162785123,0.03429330798657987,-0.0536661239493735],\"type\":\"scatter3d\"},{\"hovertemplate\":\"Score=1\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"1\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\",\"size\":5},\"mode\":\"markers\",\"name\":\"1\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0.37135306556364894,0.039357279206922696,0.33722783370470544,0.25263651647969526,0.07515787853479328,0.09883778284273662,0.10699076605120364,0.13684568790672635,0.08547927147600116,0.23107184373778109,0.08705030435995151,0.10532429296107854,0.1601411417778739,0.2800627535547185,0.08053428714882349,0.23485804651316994,0.1285664710371142,0.42696014296714824,0.09825653735996971,0.048227767540012956,0.11119860168799511,0.2376573805477724,0.12886837065296175,0.3181026904594056,0.08045651012290757,0.4931013601719509,0.1610089658652775,0.10070043588671,0.13052463259574965,0.24601380744666737,0.08509944600667346,0.18820337531700432,0.2685287800854323,0.08448586062204902,0.1703557765908978,0.09038143153309194,0.11592974832417291,0.14571123582695528,0.05939552490831639,0.1010591799759484,0.09021962606263023,0.2098965644744195,0.14669150066398903,0.06460722586687132,0.43610320517565865,0.1742283370249005,0.10744294721991078,0.04666049148205024,0.09291677845267717,0.14283906948285904,0.2453627607702877,0.21141270474122256,0.27633297537703566,0.35060972234098675,0.10725422854524058,0.1270992448438041,0.08541611045910276,0.2795008525255439,0.4260159253020945,0.17193343974534642,0.32705997665042646,0.4723191552906929,0.14573121282121018,0.11003777802418299,0.07388047577074822,0.14864158795959198,0.09000005498317613,0.10475824776183527,0.08851131691579237,0.4243991267294385,0.17477334127870714,0.29579902712382583,0.14647824645994934,0.23614196344159533,0.12344473415336867,0.07139845585424795,0.12133837456721482,0.15054176344969977,0.09483036238471684,0.07885710291845839,0.1582531701209927,0.0969848242581498,0.08663220891126006,0.06786499644176822,0.20654088233054838,0.08506167466014433,0.20607941281786019,0.2805921797319156,0.06385202248083473,0.15076989938186372,0.10678534965061176,0.1678366158560736,0.35532286051402884,0.1592411828924489],\"y\":[0.13082428961002718,-0.003854831594862003,-0.14739786676608568,0.1780642769342855,0.00025206749299712785,-0.07286265159594131,-0.01413052885027439,-0.07239070945449863,-0.032875083035150715,0.0522771043631274,-0.0254493123668239,-0.04776787398717699,-0.1869346586732344,0.31101221122617306,-0.04711051918918905,0.1329968818349699,-0.08538415138550318,0.21667252499330544,-0.045852184654140454,-0.029014530644549237,-0.03635977886467546,0.013702762408342194,-0.049246192759586,0.23478769127659774,-0.01694928771851092,0.3948090621859809,-0.16361304677334848,-0.044800607063131215,-0.03530359569513111,0.13772688734576455,-0.021124977118208457,-0.150478348375465,0.16159892768489995,-0.040803611474167265,-0.0627390765299193,-0.016442990271655883,-0.16996114458893088,-0.1179512543774996,0.004026507823796892,-0.03762117391908306,-0.02946383890713217,-0.28907538223499823,-0.031493999259083694,-0.02675592064542685,0.22577494784104665,-0.09922269216726129,-0.01028181038247081,-0.0025486759212080597,-0.04417913880645624,-0.06872757333778455,0.027055183357766542,0.03359164437503815,0.1471641759352343,0.18371443155808598,-0.031439346704622693,-0.02157895690366154,-0.01106459476872916,-0.007028616900529343,0.06625741269320029,-0.12020914489444874,0.15270938867146092,0.48884343373597516,-0.05281005763471547,-0.028031609645882034,-0.02473211494642956,-0.05514760112525677,-0.021850548711221617,-0.07084433650096754,-0.01864418206800467,0.34736179822221797,0.12893676935973522,0.22255825372895846,-0.07034299284250627,0.13133639113894552,-0.04837032890959381,-0.007833082804141104,-0.08888039091207046,-0.0496617740673179,-0.04822703007540883,-0.010443250464948081,-0.06269294246041178,-0.020393883274929994,-0.03526957024851659,-0.027539936810509417,0.047246234274579475,-0.052797662611068656,-0.19260853382612914,0.14166210614437022,-0.0026414411209958973,-0.1692635316490722,-0.014608875500161662,-0.0800189584529129,0.2979236176211711,-0.0497770229030976],\"z\":[0.27901277103521227,-0.025650463099970117,-0.17542088287972124,0.04557296311215613,-0.09931034719082259,-0.006671110843594429,-0.04542098401652553,-0.07038074739012468,-0.049681691880661155,-0.023422623942997794,-0.03858043599535336,-0.057599574100660855,-0.1448723196160141,0.11869771578326369,0.03168765700935745,0.009611370236387614,-0.07361851599784273,0.005268213293794366,-0.038389307388998005,-0.013490146029016017,-0.0631018168391671,-0.028845338009197658,-0.07588719986077659,0.06053783396167352,-0.03353906667602135,0.12419409553357738,0.13157394579953596,-0.07090415536617721,-0.06621757258039394,0.021208623070179986,-0.040875029306608926,-0.13087123473831994,0.07191000331270501,-0.03510611507972357,-0.09147734994908346,-0.025031228569021048,0.20436892739630622,-0.11357781865827267,-0.040002279683715794,-0.05300748109186463,-0.05366128095701852,0.3697293314045031,-0.07539499533749262,-0.0328388746849893,0.02434270756533955,-0.11989457476673587,-0.0703109529525515,-0.0360752771084735,-0.06486298582744163,-0.09795428879430426,-0.0776577878740215,-0.05057072873013514,0.007666254640897201,0.03197206231443697,-0.06190935138749335,-0.06466178314580873,-0.0504426213746923,-0.06902080114833918,0.16471408119450667,-0.036665226837074724,0.129684017086613,0.18673975595989886,-0.05191931621122625,-0.05114638112117185,-0.04951584234448903,-0.11491412062135518,-0.04523888806675146,-0.09574416629115139,-0.048625279966280965,0.09728318852575671,0.025591668564614565,0.051559697304562425,-0.05076187856754738,-0.012577835513871542,-0.05267179796403573,-0.033447579781015174,-0.09121984441254663,-0.0882181894206805,-0.0285304485401708,-0.05370430432921046,-0.07069852094699164,-0.04999735552188624,-0.04696770234469898,-0.03859521051111562,-0.0554972791053271,-0.051542847842809845,-0.12452372872124573,-0.026460920028914613,-0.026409207478888537,-0.1435043228448669,-0.0729599993721186,-0.08547644843585268,0.054572373924261106,-0.07392714007472785],\"type\":\"scatter3d\"},{\"hovertemplate\":\"Score=4\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"4\",\"marker\":{\"color\":\"#00cc96\",\"symbol\":\"circle\",\"size\":5},\"mode\":\"markers\",\"name\":\"4\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0.09904641413001215,0.2560479566590163,0.13663657735640813,0.1793383655681493,0.47374540058315084,0.25257656748022694,0.18768152466789575,0.13240654557910542,0.0744176097612022,0.08413382266987753,0.08275765368147407,0.26603266469415493,0.29416597827699326,0.20129304062029424,0.11086727783571826,0.22109405890307945,0.17641821296370172,0.12984797669518044,0.09950772416205794,0.08134807891663512,0.16463152095911507,0.14941815853640955,0.27037651468988727,0.16130585483544851,0.09996136623968593,0.41389684181666314,0.07357754608601183,0.26140132035166264,0.11329590231530554,0.11534594991733753,0.16440326401527247,0.3760485056171881,0.19884725117198826,0.16445266109247092,0.3682078842424964,0.5380591127313503,0.1271879665995041,0.31429265668887735,0.26189314548766546,0.20284199260454108,0.07836274268350402,0.1866782601233557,0.2125711729992411,0.11634359589578566,0.15555733380845024,0.16021665494232892,0.305247242829621,0.1898710744229741,0.19204357536424346,0.3915572333725493,0.2685393381574675,0.33547171710389295,0.15475116977736836,0.12407238304863537,0.41798643088485476,0.3813108338526297,0.06737124528619258,0.07826714918612951,0.16322249339142036,0.5079415652482134,0.09563579119666157,0.18707753321714432,0.3964622510258337,0.1477099419888544,0.3567036514485089,0.1114457683940839,0.07102465936044744,0.28003356075328867,0.14801210920700905,0.13754318835579196,0.20509853248492005,0.13065682223164124,0.26012245520542837,0.35148759491521697,0.058038676721932046,0.15946333413372962,0.15785527708201796,0.06827766929837686,0.37806589113665245,0.15417603803507707,0.13334752520104817,0.16495065918797852,0.21217834157842752,0.08031754241702944,0.12754820683728071,0.4069554684924145,0.17449721140772784,0.1233335794279419,0.1447837804805217,0.21785593627053254,0.18355173922073129,0.2897955839380984,0.09286345633633496,0.39973989433215473,0.1525921144942628,0.25082518980191276,0.12549947941425613,0.3724005716943114,0.46231539421524315,0.15725221519865581,0.13506204032163358,0.1259135685467373,0.16355805110003338,0.10815148137489243,0.35545366077726703,0.12992891436392998,0.08644519789237871,0.10667303755719211,0.18727231433927696,0.07630331274729464,0.10460830086657477,0.11625947697062497,0.13620557203071684,0.2733437093765619,0.16081445127037902,0.18677883935309328,0.10913351021194306,0.13948549584797684,0.19461846136674016,0.15329501713167887,0.21636769245339338,0.49721750626821143,0.20858647396982782,0.5137664051466091,0.18226426914608548,0.2903977873752826,0.09197922235604063,0.28230262917885046,0.17218236533724146,0.11861009703334116,0.12358417139399404,0.1681137544477272,0.4141333828733561,0.16494586897587937,0.148237447563017,0.10179824924452203,0.15751138928438818,0.3064485703397666,0.17953668027813863,0.21419852067669276,0.13089426179297095,0.12719861476635907,0.1381934344868057,0.12710022780745803,0.13992382582770838,0.19671027286010048,0.2138039831963561,0.12613527934007876,0.3496845932138308,0.3582972584881159,0.1289138649315114,0.4066516039618649,0.32072975419263505],\"y\":[-0.03622993193491904,-0.22175818583283188,-0.02569462556147776,-0.053356366191631886,0.03234518205811148,0.0356361928133216,-0.21064635353687386,-0.06895608619995051,-0.003361853055948264,-0.019053299304104772,-0.025581998111082627,-0.2964882491230036,0.1746041432721585,-0.08878318129696787,-0.05266655186846234,0.021518266282949363,-0.13668199938954634,-0.06211501243567332,-0.03882250439873892,-0.036858852478014216,-0.2751075432783277,-0.045656667484789124,-0.26282318262922255,-0.06707800764313594,-0.051105272983551484,0.2530213298266054,-0.03817988222422776,-0.22162969132384705,-0.060925121236990086,-0.0600316311937778,-0.08744431439998901,0.16783788210583767,0.013751305403291336,-0.057219412360623036,0.2854979965608941,0.3852802585812413,-0.05424894330792576,0.25180509746808816,0.0025699826116232427,-0.12958619470165736,-0.03180966326525026,-0.06058122832388973,-0.08342173202055052,-0.0354035361457666,-0.07007286429036397,-0.05289471282905733,0.16260642416335394,-0.05250090869439513,-0.2971557282785554,0.32425607066139,0.05098895054011935,0.17278091194927675,-0.09114670280947221,-0.014001013803984894,0.1845245644434599,-0.141366028213298,-0.01684033364590819,-0.038597598255926194,-0.04543920733306443,0.42710497555522614,-0.040169142497625564,-0.16604940357368403,0.20133789525439397,-0.04519816476764346,0.14313917741776455,-0.023507075433739717,-0.021887702095278197,0.06515319021757636,-0.06728047894886034,-0.08093835499513187,0.0611450244228041,-0.04853998095530907,0.14066139398539063,0.17895599506377638,-0.01299455641586676,-0.2747273110749542,-0.059470471973991836,-0.007875348899149164,-0.2987951579692582,-0.09467572424883546,-0.06446362777349429,-0.027102629346873856,-0.052864105311147984,-0.022533421801484863,-0.06105213112276859,-0.029233113328780116,-0.15169808676276272,-0.0796261118715897,-0.05678362255785769,-0.2962137148538588,0.0851447076831414,0.08750987172776761,-0.07157330908678114,0.21563591313070257,-0.06794491418571966,-0.1632064970894397,-0.07265118246997321,0.28353294806567886,0.3748869140464495,-0.06973716693809556,-0.03812888005784313,-0.053294574681167176,-0.15480048159396328,-0.07774806991622478,-0.14217628843192343,-0.03785760246969682,-0.04877948244916802,-0.03651380056954122,-0.19408043078682896,-0.029034889361006514,-0.008843413685357258,-0.012877869902639942,-0.03886737960059479,-0.2817801878603208,-0.08074923718030193,-0.2681656455062082,-0.028719691915321168,-0.08930504559432,-0.09436448158692871,-0.09561869006447084,0.09181747632006183,0.32078592066550893,-0.2823765496632432,0.33273854413668064,-0.11785710598762902,0.13358084641802373,-0.03593057496971342,0.11138957217449542,-0.10273807218470285,-0.04850573210340906,-0.039673810834179195,-0.0758184235639157,0.10256606897734369,-0.12333918424108836,-0.0590723247554269,-0.045170796364608586,-0.05292555268066773,-0.1776465476115907,-0.07194123517504016,-0.07682987028456156,-0.0473246312696387,-0.03192742044455101,-0.0944088495011427,-0.038471525962455115,-0.04460502469693317,-0.26367332383167996,-0.22958049546258896,-0.07526595129100988,0.04242320328342482,0.07998313373765764,-0.08587753638753676,-0.030187414536218482,0.023084988022984372],\"z\":[-0.07224799592405041,-0.10827686824768576,-0.0749463559684703,-0.06671450159856654,-0.029308401406957316,-0.02664952024415485,-0.09251057810028118,-0.10112164337232483,-0.06675356670621659,-0.049932919236480064,-0.039005888664864194,0.24208276177945326,0.010865850781310232,-0.1226855677974392,-0.05456943597795871,-0.04459933365149612,-0.0474732369550883,-0.0747678488021101,-0.050120645147595524,-0.030218861832120164,0.4339415021229126,-0.07262023551836919,0.21563082294624433,-0.08612901979187759,-0.04666130468265352,0.06324810280093332,-0.03333558552574655,-0.15737498255636803,-0.06938672589450606,-0.07015482079838897,-0.05266920364597989,0.03743599252081961,-0.03290159458264681,-0.10519100782496202,0.02324433571735523,0.09653523157572118,-0.08034448572500764,0.0699958393166066,0.0018363973297187285,-0.15624100872919702,-0.04985346098758384,-0.07756833621739666,-0.08891192366267638,-0.06694036637962307,-0.0754114731434325,-0.07863519471558185,0.0067662280612737135,0.10129008079023316,0.17615245454109207,0.1013384641490422,-0.009516298114607535,0.014181709277109482,-0.06623452548248712,-0.13058787228123847,0.05605767056636373,-0.05002326877325141,-0.023947965208470888,-0.05723688994078414,-0.09639048710066253,0.11776363124201925,-0.04843091739375803,0.08404764180245695,0.020622703604120943,-0.06683346324206522,-0.1067205703102867,-0.07001393515106612,-0.05557707828731853,0.06534168831193711,-0.10963932895657044,-0.06257487781295545,0.03116306681313223,-0.03973719429338153,-0.02820942155277015,-0.0015268202462268466,-0.025940404691138695,0.36463627806852844,-0.0854838230621044,-0.024447914817141276,0.42153138224767805,-0.095919024211547,-0.055694255317735045,-0.10308125088090468,-0.2008537635755108,-0.03467023313886735,-0.04716847142009636,0.4607266194756059,-0.15246433977684146,-0.08257286794348946,-0.05471899705014708,0.19949091482148887,0.006630128490218518,-0.02571716209828088,-0.062262657240463294,0.019032936659299487,-0.06432273869869523,0.41413194596669434,-0.056830510294958954,0.057053471528246275,0.11641716779506227,-0.09152550464074945,-0.12820780634868686,-0.09003584169309509,0.12798191836157347,-0.04153010074823964,-0.1324120246005144,-0.116967563888975,-0.014962239811677555,-0.05061406217374054,-0.1583119596383535,-0.0493219226163056,-0.047911522742029554,-0.08035435638481987,-0.07719590226911119,0.24226946899949006,-0.051246205644453105,0.2799120254840091,-0.08827201338483445,-0.06440969424065904,-0.08421415292493209,-0.03782212843354048,0.01781581445261356,0.04923835111040558,0.2962451563850349,0.11346367122524194,-0.05935749193567051,-0.014361154104229723,-0.04553119780180703,-0.014066431532177714,-0.11580877645131188,-0.0864414819551608,-0.06672583489147285,-0.07367882554336327,-0.008413168065459777,-0.130586165326003,-0.05713144212541894,-0.08130717154751589,-0.10358800353010732,0.38180596873474876,-0.12390130037597205,-0.13346380289136492,-0.094195019389199,-0.07772127406689469,-0.06094392079290797,-0.11120284219452511,-0.0714604093431453,0.30486759602839986,-0.14771028548115833,-0.03175103501331738,0.1094433293690395,0.03878505838071532,-0.09316379308188441,0.2075486860079107,-0.05898137155086409],\"type\":\"scatter3d\"},{\"hovertemplate\":\"Score=3\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"3\",\"marker\":{\"color\":\"#ab63fa\",\"symbol\":\"circle\",\"size\":5},\"mode\":\"markers\",\"name\":\"3\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0.15780193809776288,0.025618548940977134,0.1643225521348095,0.33026816474508686,0.15162377960134132,0.17061985035913566,0.27704683127278307,0.17569076956972876,0.12022793433020251,0.08941595479776808,0.17145933964961094,0.438480899777246,0.19397658613960309,0.13381711939790333,0.0965735503051987,0.30605794083213095,0.2306374543181936,0.24749678642083245,0.26649493217882986,0.21130532414297243,0.4352647212883296,0.1644231635376868,0.15945794265055946,0.25175354214264845,0.13416457519106673,0.11884211491127437,0.06206175014706986,0.20118366188704728,0.34261217269221683,0.1340624293267445,0.15851309095728566,0.17112558149094417,0.39686519824690547,0.16959408874107987,0.0744814698837649,0.12362468004124338,0.36647900507674097,0.193297425171213,0.30502532531495663,0.10452331314920642,0.2328217567781128,0.22897004525924916,0.11221411903373753,0.28354055936683425,0.11483853441896864,0.1446431589836243,0.11092140236021389,0.08870747828319361,0.169341433938857,0.22554024218431457,0.1539255443960291,0.09517511491237649,0.1411333321823673,0.2098683368635294,0.19862108838978954,0.26788935504840045,0.30910092671280287,0.5599562148133842,0.07248287046667062,0.2165799622716934,0.35794574429112724,0.41385040681085744,0.0883661931876747,0.2573179903448479,0.3159350874952103,0.29200749963155387,0.1998657542139448,0.09644375519793279,0.11451930242747425,0.1327994050773619,0.5493238831724448,0.26351596692695883],\"y\":[-0.06150927288848602,-0.0014900622907992173,-0.06014407416186823,0.06474379896377198,-0.05502131456344494,-0.020528887058302785,-0.022850457730293212,-0.042632601907217446,-0.018040221216976644,-0.03381144667928343,-0.06613210469013639,0.29988795958822806,-0.09041645108286522,-0.15557254298571796,-0.11285044835128,0.1809216429861514,-0.1476860542199292,-0.12410308426846997,0.0855525882592885,-0.23040769396400185,0.019567602275180184,-0.0800624277025826,-0.046032118435241104,0.18016405303649904,-0.06128994549612834,-0.0558443152026228,-0.023084475379728533,-0.09012315339226779,0.17407251820095718,-0.06010579147336788,-0.11362018077546701,-0.016547642583919178,0.4038403938430357,-0.18105288788431115,-0.016681237618924608,-0.052369797858433785,0.16909541895446487,-0.25799444471217525,-0.21585466275473186,-0.03324560674916627,-0.043970654851702304,-0.1304253082079919,-0.04632012381364513,0.149277516702897,-0.03327190709279981,-0.07435833142586014,-0.08412740972280304,-0.03792786134048618,-0.04468710524560839,-0.2870382912760676,-0.06823109219626165,-0.046517289839725244,-0.06041184189770268,-0.22639762014173986,0.1291469248924191,-0.4084875160633382,0.1527681243000459,0.4872925993680803,-0.020293916141412273,-0.2891273142446971,0.18550313388642764,0.07975193590489539,-0.020833184582151682,0.0947707429334589,0.08285202702424418,-0.03387619980452592,0.05325899225936801,-0.039037111120973494,-0.06419442846400111,-0.07447024738118233,0.34928741420935744,0.10084999445814802],\"z\":[-0.06292396684165243,-0.013451950698805283,-0.08913936681657204,-0.0694168084013381,-0.05275958490437972,-0.13337699500094644,-0.08925959370276236,-0.10120781066717384,-0.03128473508873064,-0.04899032721178261,-0.07974088502381584,0.04684036942476545,-0.0614170775620333,-0.04752268719021735,-0.06416083371465206,0.019948971478107667,0.03150954719487331,-0.10280451751724859,0.03476557796543743,0.1211631949115082,-0.04061752979492452,-0.06571132616669027,-0.08587725535967354,0.048128214273423724,-0.06500812818723628,-0.05723301054655667,-0.05492807491092642,-0.07787803291289032,-0.0941250982779659,-0.06562535586104261,0.032576567855020076,-0.13674946193452353,0.12893980837601096,-0.12798882900489766,-0.03107847141155866,-0.08289657272343216,-0.040832587644571997,-0.16882247537090306,0.332760175710432,-0.061549640372385715,0.2329865107266126,-0.0879643154936765,-0.057286176717436396,-0.010900646104935944,-0.05337551027286285,-0.07269771557562292,-0.09187289558140313,-0.05124389975120054,-0.1456840790504038,0.33626298075068184,-0.0833384555938556,-0.05080239565968872,-0.06010731638769595,-0.11865874819291738,0.030234617808632402,0.5394692025563839,-0.03149258785455787,0.13231426781330827,-0.041146396577615645,0.3446633799294389,0.01226633876904076,-0.03608197500586039,-0.033707529393673136,-0.012826071950984334,-0.0942480298953928,-0.0681321618726118,-0.044656712664067906,-0.018991752739186886,-0.013841832628858033,-0.07178281700562072,0.13605088880974991,-0.026803320932435707],\"type\":\"scatter3d\"},{\"hovertemplate\":\"Score=2\\u003cbr\\u003ex=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"2\",\"marker\":{\"color\":\"#FFA15A\",\"symbol\":\"circle\",\"size\":5},\"mode\":\"markers\",\"name\":\"2\",\"scene\":\"scene\",\"showlegend\":true,\"x\":[0.09470284158478333,0.20734968983474472,0.09555265821702894,0.22548885746747427,0.12852734258750884,0.08393067949913849,0.29119840946041586,0.18439677024894557,0.161972297456771,0.45622648315163233,0.12394445633342586,0.1581871857892069,0.13412727063336594,0.176027442128369,0.39116825059307936,0.20444362434933097,0.2200616862051127,0.0882214567035155,0.21360353774285393,0.48916929724258507,0.20500333216813077,0.22349655549058692,0.06283989822158227,0.3811392417439375,0.4026775606879237,0.12353281358739762,0.14123087413781954,0.11772926631840401,0.19594963633970752,0.1633567417742308,0.19832527781640352,0.0984879005143625,0.1292257919520203,0.1430438670907924,0.1620311285058259,0.07992735980861275,0.10698401605264257,0.09021451161755904,0.10842858473892465,0.07028266553584989,0.2518323042158127,0.1779442856282975,0.11063567973293977,0.1586463568335612,0.11818418959033694,0.14130339834319097],\"y\":[-0.008137741947631734,-0.14262226663700617,-0.03345058637839393,-0.22025090896587798,-0.009728426064002437,-0.018526633750195587,0.18384871730832228,-0.06791755867146171,-0.06117054630047715,0.29377832638839996,-0.04917812116957178,-0.027746148452268398,-0.06299208518415532,-0.14711975986999445,-0.19134989470645725,-0.08492429414978665,0.06719260601836036,-0.0256417549343054,0.018820059364246397,0.32262326676396763,-0.16965604176198085,-0.09885870750959687,-0.015985460270036222,0.1989840400483415,0.056823220284805284,-0.048318411234721276,-0.0394270032298042,-0.1147061315611032,-0.07864021859332816,-0.07850734466828578,0.050254046244466236,-0.021824453243488567,-0.06508472805788856,-0.14568331092205744,-0.05965147792255066,-0.1030551110315518,-0.03253535201591029,-0.06734048082415299,-0.06171780952742619,-0.029155664910723102,-0.2328509464727486,0.0696672111947648,-0.046560201537228556,-0.0717949445974567,-0.034263366882560355,-0.04964531602190997],\"z\":[-0.07021912401587982,-0.1504564001825813,-0.0660937319228134,-0.18230724475501908,-0.09643345892820139,-0.03290545045302127,0.03767093076552069,-0.11987454080180482,-0.08473010260846685,0.030153878350216518,-0.060308250816781046,-0.08505194646072342,-0.08480791424637563,-0.13076889187326482,0.49237549658808816,-0.1123148931109793,0.057339587808581866,-0.03526369112844918,-0.05774868291096872,0.06544926355036944,-0.1123268469116375,0.026600252874125617,-0.04146587144163996,0.06485472448438499,-0.06853362427298099,-0.06030450024349093,-0.06280589610820458,-0.07697586724945393,-0.11341212121450267,-0.04896866639118515,-0.031351238790362085,-0.0426856794493298,-0.07009981185326683,0.10033832222381509,-0.06976384516092202,0.10941442305834057,-0.05970723401459881,-0.057787053806060945,-0.03268398536653106,-0.045296448835660946,-0.11025927569345804,0.043875881971339896,-0.009351038061237894,-0.08854785131225652,-0.0452650267508611,-0.041256415134075845],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}}},\"legend\":{\"title\":{\"text\":\"Score\"},\"tracegroupgap\":0},\"title\":{\"text\":\"3D Visualization of Review Embeddings by Rating\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3abc4373-2fff-4012-9a93-2f425df57e56');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preprocessing Pipeline\n",
        "To prepare the text for modeling, we need a robust preprocessing pipeline. We will:\n",
        "- Normalize text case: Convert to lowercase (if enabled).\n",
        "- Remove HTML tags: Some reviews may contain HTML or markup, which we strip out.\n",
        "- Remove Markdown/URLs: If any markdown formatting or URLs exist, remove them.\n",
        "- Remove special characters/punctuation: Keep only letters (and optionally numbers if needed; here primarily letters to focus on words).\n",
        "- Tokenize and remove stopwords: Remove common words that may not contribute to sentiment (optional, based on config).\n",
        "- Lemmatize/Stemming: Reduce words to their base form (lemma) or root form (stem) to reduce sparsity (optional, based on config).\n"
      ],
      "metadata": {
        "id": "ro67p75oiAjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll implement a clean_text function that applies these steps according to PREPROCESS_CONFIG. This allows easy toggling of each step."
      ],
      "metadata": {
        "id": "qSKTJy0-iK-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure NLTK resources are available\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "\n",
        "# Preprocessing function\n",
        "def clean_text(text, config=PREPROCESS_CONFIG):\n",
        "    \"\"\"Clean text according to the configuration dictionary.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        text = str(text) if text is not None else \"\"\n",
        "    # Lowercasing\n",
        "    if config.get(\"lowercase\", False):\n",
        "        text = text.lower()\n",
        "    # Remove HTML tags\n",
        "    if config.get(\"remove_html\", False):\n",
        "        text = re.sub(r'<[^>]+>', ' ', text)\n",
        "    # Remove markdown links (e.g., [text](url)) and other markdown special chars\n",
        "    if config.get(\"remove_markdown\", False):\n",
        "        # Remove link markdown format\n",
        "        text = re.sub(r'\\[.*?\\]\\(.*?\\)', ' ', text)\n",
        "        # Remove residual markdown symbols like *, _, `\n",
        "        text = re.sub(r'[\\*_`]', ' ', text)\n",
        "    # Remove non-alphabet characters (keeping spaces)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    # Tokenize text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # Remove stopwords if enabled\n",
        "    if config.get(\"remove_stopwords\", False):\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        # (Optional consideration: we might remove 'not' from stop_words to keep negation)\n",
        "        if 'not' in stop_words:\n",
        "            stop_words.remove('not')\n",
        "        tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Apply lemmatization or stemming if enabled\n",
        "    if config.get(\"lemmatize\", False):\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    if config.get(\"stem\", False):\n",
        "        stemmer = PorterStemmer()\n",
        "        tokens = [stemmer.stem(word) for word in tokens]\n",
        "    # Join tokens back to string\n",
        "    return \" \".join(tokens)\n"
      ],
      "metadata": {
        "id": "HHB7c3LMiMKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll apply this cleaning to the text data. To avoid data leakage, we will fit any vocabulary-based processing (like removing stopwords or lemmatization) globally since those do not require fitting on training data specifically. Cleaning can be done for all sets, but we must be careful not to use future (test) data in any learned transformation. Here, cleaning is a stateless operation so it's safe to apply to all. We'll proceed to split the data into training and testing sets (and a validation set) before applying transformations that involve fitting (like vectorizers)."
      ],
      "metadata": {
        "id": "MFPwT0XxiOAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train, validation, and test sets\n",
        "# We will simulate a Kaggle scenario: use a portion as \"test\" (to submit predictions for)\n",
        "train_full_df, test_df = train_test_split(df, test_size=0.2, stratify=df['Score'], random_state=SEED)\n",
        "train_df, val_df = train_test_split(train_full_df, test_size=0.1, stratify=train_full_df['Score'], random_state=SEED)\n",
        "\n",
        "print(f\"Train set: {len(train_df)} reviews, Validation set: {len(val_df)} reviews, Test set: {len(test_df)} reviews\")\n",
        "\n",
        "# Apply text cleaning to train, val, test\n",
        "train_df['clean_text'] = train_df['Text'].apply(lambda x: clean_text(x, PREPROCESS_CONFIG))\n",
        "val_df['clean_text'] = val_df['Text'].apply(lambda x: clean_text(x, PREPROCESS_CONFIG))\n",
        "test_df['clean_text'] = test_df['Text'].apply(lambda x: clean_text(x, PREPROCESS_CONFIG))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VescdhSBiP-M",
        "outputId": "d463b8b3-4b3c-4b96-d2f3-71c6631c27b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: 222573 reviews, Validation set: 24731 reviews, Test set: 61827 reviews\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After cleaning, let's verify the transformation on a sample of the text:"
      ],
      "metadata": {
        "id": "ortkW4_piTBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# before-and-after example of cleaning\n",
        "print(\"Original review example:\\n\", train_df['Text'].iloc[0])\n",
        "print(\"\\nCleaned review example:\\n\", train_df['clean_text'].iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLUaWlM7iU7o",
        "outputId": "5c294eac-6541-4f7e-963d-8b09bbfaf02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original review example:\n",
            " Just like the previous 2-pack listing for this product which was removed, this is just TOO EXPENSIVE.  You can buy it at retail (Starbucks, Target, etc.) for around $7.  I absolutely love this tea - it's by far my favorite - but I'm unwilling to buy it through Amazon at these prices.\n",
            "\n",
            "Cleaned review example:\n",
            " like previous pack listing product removed expensive buy retail starbucks target etc around absolutely love tea far favorite unwilling buy amazon prices\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a new column 'clean_text' that contains the normalized and tokenized review text, ready for feature extraction.\n",
        "\n",
        "_(We chose to remove stopwords and perform lemmatization by default. This helps reduce noise and dimensionality. However, we kept negation words like \"not\" in the text because they carry sentiment information.)_"
      ],
      "metadata": {
        "id": "cQrIzf50iYep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Feature Engineering"
      ],
      "metadata": {
        "id": "6qh4r5pjiefA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With cleaned text, the next step is to convert words into numerical features that models can use. We will implement a flexible feature engineering pipeline that can produce features using various approaches:\n",
        "- Bag-of-Words (CountVectorizer): Converts text to high-dimensional sparse vectors of word counts.\n",
        "- TF-IDF Vectorizer: Similar to Count, but weights terms by inverse document frequency to downweight common words.\n",
        "- Word Embeddings: Use pre-trained word vectors (e.g., GloVe or Word2Vec) to represent each word, and aggregate for the text (e.g., average of word embeddings).\n",
        "- Transformer Embeddings: Use modern language models (like BERT or ModernBERT) to get contextual embeddings for entire sentences or use them directly with a classification head."
      ],
      "metadata": {
        "id": "zQO7mC69iifV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will demonstrate multiple methods below. For traditional ML models, TF-IDF is a strong baseline. We will also prepare data for neural network models (sequence of word indices for embedding layers) and set up transformer tokenization for BERT-based models."
      ],
      "metadata": {
        "id": "i1M7mXBsimer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 TF-IDF and Count Vectorizer Features"
      ],
      "metadata": {
        "id": "tVAjmhsuiop5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use TF-IDF Vectorizer on the cleaned text\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=20000)  # limit features for efficiency\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['clean_text'])\n",
        "X_val_tfidf = tfidf_vectorizer.transform(val_df['clean_text'])\n",
        "X_test_tfidf = tfidf_vectorizer.transform(test_df['clean_text'])\n",
        "\n",
        "print(\"TF-IDF features shape (train):\", X_train_tfidf.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhBLH2dYitkh",
        "outputId": "c8b7b8af-0cab-4a64-ec3f-158aa00b9b78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF features shape (train): (222573, 20000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we wanted to use raw counts instead of TF-IDF (for certain models like Naive Bayes which can work well with raw counts), we could similarly use CountVectorizer:"
      ],
      "metadata": {
        "id": "0hNN4Nuyiv-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer(max_features=20000)\n",
        "X_train_count = count_vectorizer.fit_transform(train_df['clean_text'])\n",
        "X_val_count = count_vectorizer.transform(val_df['clean_text'])\n",
        "X_test_count = count_vectorizer.transform(test_df['clean_text'])\n",
        "print(\"CountVectorizer features shape (train):\", X_train_count.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMahn7BliyrT",
        "outputId": "d9368f52-dacf-4c52-ed0b-ba0634c7f02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer features shape (train): (222573, 20000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*(We will primarily use TF-IDF for the upcoming models, but CountVectorizer is prepared in case we want to use it for certain algorithms like MultinomialNB.)*"
      ],
      "metadata": {
        "id": "i5yyEl5Wi0b9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Word Embedding Features\n",
        "We can leverage pre-trained word embeddings for a dense representation. For example, GloVe provides vectors for many English words. We'll demonstrate how to use a pre-trained GloVe model to get an embedding for each review by averaging the embeddings of words in the review."
      ],
      "metadata": {
        "id": "C9q5R8A7i32y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_index = {}\n",
        "try:\n",
        "    glove_model = api.load(\"glove-wiki-gigaword-50\")  # download a pretrained model (requires internet)\n",
        "    for word in glove_model.key_to_index:\n",
        "        embedding_index[word] = glove_model[word]\n",
        "    embedding_dim = 50\n",
        "    print(\"Loaded GloVe vectors.\")\n",
        "except Exception as e:\n",
        "    print(\"Pre-trained embeddings not loaded (proceeding without external download).\", str(e))\n",
        "    glove_model = None\n",
        "    embedding_dim = 50  # default dim if needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sK14HKDGi-jp",
        "outputId": "2d0c26b0-bf74-4cac-9ab9-d0bd8e1d6d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded GloVe vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, if we have embedding_index, we can compute average vectors:"
      ],
      "metadata": {
        "id": "Y7N0-RhfjVOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_embedding_avg(text, embed_index=embedding_index, dim=embedding_dim):\n",
        "    if not embed_index:\n",
        "        # If no pre-trained embeddings loaded, return a zero vector\n",
        "        return np.zeros(dim)\n",
        "    words = text.split()\n",
        "    valid_vectors = [embed_index[w] for w in words if w in embed_index]\n",
        "    if not valid_vectors:\n",
        "        return np.zeros(dim)\n",
        "    # Average the word vectors\n",
        "    return np.mean(valid_vectors, axis=0)\n",
        "\n",
        "# Compute embedding features for train/val sets (using cleaned text)\n",
        "if glove_model:\n",
        "    X_train_embed = np.vstack(train_df['clean_text'].apply(text_to_embedding_avg).values)\n",
        "    X_val_embed = np.vstack(val_df['clean_text'].apply(text_to_embedding_avg).values)\n",
        "    X_test_embed = np.vstack(test_df['clean_text'].apply(text_to_embedding_avg).values)\n",
        "    print(\"Word embedding feature matrix shape (train):\", X_train_embed.shape)\n",
        "else:\n",
        "    X_train_embed = X_val_embed = X_test_embed = None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvpRAGwfjWhX",
        "outputId": "7fd5d3c5-c9b6-40c4-d669-35ec4bf14d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word embedding feature matrix shape (train): (222573, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.3 Text to Sequence (For Deep Learning Models)\n",
        "For neural network models like CNNs or LSTMs, we will convert text into sequences of integer indices corresponding to words. We'll use Keras Tokenizer to build a vocabulary and encode the reviews as sequences, then pad them to a fixed length."
      ],
      "metadata": {
        "id": "b9LmFgMjjnho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare text sequences for deep learning models (CNN/LSTM)\n",
        "MAX_VOCAB_SIZE = 20000   # maximum number of words to keep in tokenizer\n",
        "MAX_SEQ_LENGTH = 100     # maximum length of sequence (in words)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_df['clean_text'])\n",
        "\n",
        "# Convert texts to sequences of integers\n",
        "X_train_seq = tokenizer.texts_to_sequences(train_df['clean_text'])\n",
        "X_val_seq = tokenizer.texts_to_sequences(val_df['clean_text'])\n",
        "X_test_seq = tokenizer.texts_to_sequences(test_df['clean_text'])\n",
        "\n",
        "# Pad sequences to the same length\n",
        "X_train_seq = pad_sequences(X_train_seq, maxlen=MAX_SEQ_LENGTH, padding='post', truncating='post')\n",
        "X_val_seq = pad_sequences(X_val_seq, maxlen=MAX_SEQ_LENGTH, padding='post', truncating='post')\n",
        "X_test_seq = pad_sequences(X_test_seq, maxlen=MAX_SEQ_LENGTH, padding='post', truncating='post')\n",
        "\n",
        "print(\"Sequential data shape (train):\", X_train_seq.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8hMG3yNjt_F",
        "outputId": "6bf39d8a-fb1f-4614-e490-1742c156c178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential data shape (train): (222573, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We keep MAX_SEQ_LENGTH relatively modest (100 words) for efficiency. Many reviews will be longer, but the model can still capture a lot of information from the first 100 words. (This **SHOULD BE** tuned; using more may improve results at the cost of memory and training time.)"
      ],
      "metadata": {
        "id": "b1FYGz5Rjvh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.4 Transformer Tokenization for BERT-like models\n",
        "For transformer models, we'll use Hugging Face's AutoTokenizer to prepare inputs (with attention masks etc.). We'll demonstrate with a DistilBERT (a lighter BERT) model name, which can be swapped with BERT or ModernBERT."
      ],
      "metadata": {
        "id": "zmZ1-ENUj4LV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare tokenizer and dataset for a transformer model (e.g., DistilBERT)\n",
        "transformer_model_name = \"answerdotai/ModernBERT-base\"  # can be changed to \"bert-base-uncased\" or \"answerdotai/ModernBERT-base\"\n",
        "transformer_tokenizer = AutoTokenizer.from_pretrained(transformer_model_name)\n",
        "\n",
        "# Tokenize the text for transformer (using original text, not heavily cleaned, to preserve context)\n",
        "def tokenize_for_transformer(texts, tokenizer, max_length=128):\n",
        "    return tokenizer(texts.tolist(), padding=True, truncation=True, max_length=max_length, return_tensors=\"np\")\n",
        "\n",
        "train_encodings = tokenize_for_transformer(train_df['Text'], transformer_tokenizer)\n",
        "val_encodings = tokenize_for_transformer(val_df['Text'], transformer_tokenizer)\n",
        "test_encodings = tokenize_for_transformer(test_df['Text'], transformer_tokenizer)\n",
        "print(\"Example tokenized input keys:\", train_encodings.keys())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289,
          "referenced_widgets": [
            "bea90ea2f2bd4ee195f8f3723c809245",
            "fc924b1a096d472cb1fca2c01112a21b",
            "c010633ea8244a28ac5753668e19f4c9",
            "9bffde794062408a9202f2425862ae1c",
            "03f1c07ab2a2497b8be974df3f84dc03",
            "5e85157d2053449d8d63e34240863b22",
            "0fc47f238412465b90b4d57567cc9806",
            "1480688c7d2a4444a61769810ec19a0e",
            "43a9827a18424bdca4230fb21e5e872a",
            "5015382a8144478c8d3845194ff2f309",
            "380a4a92a82d4fa788ab02d82fb1f748",
            "4d06f04257dc4de38c6bcdda5ddfb656",
            "4208bbae89214fb79dd7ecf2afb420dc",
            "f9a8e22432a142c2ba4fba4640543084",
            "ff961ec92f9b4d2b9bf2e57da309b052",
            "ede23b911d6d4118be9cce9241bdb0f5",
            "8a28eb62554c4970bb255f63bc8788af",
            "dfa630f0f1bf402c89c2054cf14dfaa8",
            "250854eb67b7406db664979c7f281fa7",
            "5bdd067d5e74407181526a9330998837",
            "b149f02565624f75a62de1113add960a",
            "5e055e7331314f63a8aa4510d15a1b4f",
            "0ea588a5cef44177b6618ed46912767b",
            "aafb28a643e747f881f0924a054d9545",
            "926204ffde13445b98dd8d5f17e3c729",
            "ffc78ca0896f4291badcf5dafc6aab35",
            "5bb639e692a04f0eb642fb774baca649",
            "fcc046f5fd7844ffacbaad103e50ce77",
            "a564e4da9b8e440987a1d0a3a01b4461",
            "736392b2689e455ea088f81fbc189320",
            "ba32cdd6e79547869043f2ac7b003e52",
            "3fb18d01222b446ba0c7acab4361458b",
            "77dc0dfbdbcf4a3cb09c22858ba30730"
          ]
        },
        "id": "2uvT-x08j_2B",
        "outputId": "d01cc383-7e63-4440-f17a-75d5e4cc36a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning:\n",
            "\n",
            "\n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/20.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bea90ea2f2bd4ee195f8f3723c809245"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.13M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fc924b1a096d472cb1fca2c01112a21b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ea588a5cef44177b6618ed46912767b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example tokenized input keys: dict_keys(['input_ids', 'attention_mask'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We limited max_length to 128 tokens for BERT for efficiency (can be increased if needed). The tokenize_for_transformer function returns dictionaries containing input IDs, attention masks, etc., suitable for model input."
      ],
      "metadata": {
        "id": "VjgE8fjDkEvB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " let's create torch.Dataset objects for train and val:"
      ],
      "metadata": {
        "id": "iA1gdBh1kJY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewsDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels=None):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels is not None:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "# Create dataset objects\n",
        "train_dataset = ReviewsDataset(train_encodings, train_df['Score'].astype(int).values - 1)  # labels 0-4\n",
        "val_dataset = ReviewsDataset(val_encodings, val_df['Score'].astype(int).values - 1)\n",
        "test_dataset = ReviewsDataset(test_encodings, None)"
      ],
      "metadata": {
        "id": "GU0ndgbWkFlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*(We subtract 1 from labels because we'll treat 1-5 as 0-4 for zero-based class indices in PyTorch. We won't actually train on test_dataset since it has no labels, it's only for prediction.)*"
      ],
      "metadata": {
        "id": "MlegQdeEkPS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have prepared data for:\n",
        "TF-IDF / Count (sparse matrices)\n",
        "Embedding averages (dense vectors, if available)\n",
        "Sequences for Keras models\n",
        "Encodings for transformers\n",
        "We can now move on to building and training models.\n"
      ],
      "metadata": {
        "id": "MVi3Ae7dkRtF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Model Zoo\n",
        "In this section, we will train a diverse set of models on the training data and evaluate them on the validation set. We'll include:\n",
        "- Traditional ML models: Logistic Regression, Support Vector Machine, Naive Bayes, Random Forest, AdaBoost, XGBoost, LightGBM.\n",
        "- Neural network models: A simple Dense Neural Network (MLP), a 1D CNN, an LSTM RNN.\n",
        "- Transformer models: Fine-tuning a pre-trained transformer (DistilBERT or BERT, with possibility to use ModernBERT)."
      ],
      "metadata": {
        "id": "L_rG8SMvkR55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll also ensure to apply class balancing if BALANCE_CLASSES is True, typically by using class_weight='balanced' or similar options. Let's prepare the target variables and class weights:"
      ],
      "metadata": {
        "id": "I_yzxlYEkZ4h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's prepare the target variables and class weights:"
      ],
      "metadata": {
        "id": "msQOzXL5kbxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare targets for training and validation\n",
        "y_train = train_df['Score'].astype(int).values\n",
        "y_val = val_df['Score'].astype(int).values\n",
        "\n",
        "# If balancing classes, compute class weights\n",
        "if BALANCE_CLASSES:\n",
        "    classes = np.unique(y_train)\n",
        "    cw = class_weight.compute_class_weight('balanced', classes=classes, y=y_train)\n",
        "    class_weights = {cls: weight for cls, weight in zip(classes, cw)}\n",
        "    print(\"Class weights for balancing:\", class_weights)\n",
        "else:\n",
        "    class_weights = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkU8srVnkcsq",
        "outputId": "1ea2263a-a16a-404a-9e67-d6d1f85b1b0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class weights for balancing: {1: 2.1677428780131485, 2: 3.796230598669623, 3: 2.653943838311572, 4: 1.4090911968598652, 5: 0.3135979372728041}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's train each model and record the performance."
      ],
      "metadata": {
        "id": "5B7PJb5uke9G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 Traditional Machine Learning Models\n",
        "We'll train and evaluate: **Logistic Regression**, **SVM**, **Naive Bayes**, **Random Forest**, **AdaBoost**, **XGBoost**, **LightGBM**. These will all use TF-IDF features for fairness (except Naive Bayes where we'll use Count features to align with its assumptions)."
      ],
      "metadata": {
        "id": "VCe9TDYAkfzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary to store model performances\n",
        "model_performance = {}\n",
        "y_train_keras = (y_train - 1)\n",
        "y_val_keras = (y_val - 1)"
      ],
      "metadata": {
        "id": "UBmL96ERY2Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "logreg = LogisticRegression(max_iter=3000, class_weight=('balanced' if BALANCE_CLASSES else None), random_state=SEED,n_jobs=-1)\n",
        "logreg.fit(X_train_tfidf, y_train)\n",
        "pred_lr = logreg.predict(X_val_tfidf)\n",
        "model_performance['Logistic Regression'] = {\n",
        "    \"F1_weighted\": f1_score(y_val, pred_lr, average='weighted'),\n",
        "    \"Accuracy\": accuracy_score(y_val, pred_lr)\n",
        "}"
      ],
      "metadata": {
        "id": "nZ_-30kpkuXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(\n",
        "    class_weight='balanced' if BALANCE_CLASSES else None,\n",
        "    max_iter=3000,\n",
        ")\n",
        "svm.fit(X_train_tfidf.astype('float32'), y_train.astype('float32'))\n",
        "\n",
        "pred_svm = svm.predict(X_val_tfidf)\n",
        "model_performance['Linear SVM'] = {\n",
        "    \"F1_weighted\": f1_score(y_val, pred_svm, average='weighted'),\n",
        "    \"Accuracy\": accuracy_score(y_val, pred_svm)\n",
        "}"
      ],
      "metadata": {
        "id": "pzgRZXBm0Dwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes (Multinomial NB) - use Count features for NB\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_count, y_train)\n",
        "pred_nb = nb.predict(X_val_count)\n",
        "model_performance['Multinomial NB'] = {\n",
        "    \"F1_weighted\": f1_score(y_val, pred_nb, average='weighted'),\n",
        "    \"Accuracy\": accuracy_score(y_val, pred_nb)\n",
        "}\n"
      ],
      "metadata": {
        "id": "mRVsG16f0Fd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest\n",
        "rf = RandomForestClassifier( n_jobs=-1, n_estimators=100, max_depth=25, class_weight=('balanced' if BALANCE_CLASSES else None), random_state=SEED)\n",
        "rf.fit(X_train_tfidf, y_train)\n",
        "pred_rf = rf.predict(X_val_tfidf)\n",
        "model_performance['Random Forest'] = {\n",
        "    \"F1_weighted\": f1_score(y_val, pred_rf, average='weighted'),\n",
        "    \"Accuracy\": accuracy_score(y_val, pred_rf)\n",
        "}"
      ],
      "metadata": {
        "id": "XzUu9uWL0HUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AdaBoost (with decision tree stumps)\n",
        "ada = AdaBoostClassifier(n_estimators=100, random_state=SEED)\n",
        "ada.fit(X_train_tfidf.toarray(), y_train)  # AdaBoost requires dense input\n",
        "pred_ada = ada.predict(X_val_tfidf.toarray())\n",
        "model_performance['AdaBoost'] = {\n",
        "    \"F1_weighted\": f1_score(y_val, pred_ada, average='weighted'),\n",
        "    \"Accuracy\": accuracy_score(y_val, pred_ada)\n",
        "}"
      ],
      "metadata": {
        "id": "YtZMqPpa0Ia6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "7cc43977-e932-4913-8049-591c776b49fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-e4fba5e26460>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# AdaBoost (with decision tree stumps)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mada\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# AdaBoost requires dense input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpred_ada\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m model_performance['AdaBoost'] = {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;31m# Boosting step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[1;32m    168\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \"\"\"\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         super()._fit(\n\u001b[0m\u001b[1;32m   1025\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    470\u001b[0m             )\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_values_in_feature_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svd = TruncatedSVD(n_components=300, random_state=SEED)\n",
        "X_train_reduced = svd.fit_transform(X_train_tfidf)\n",
        "X_val_reduced = svd.transform(X_val_tfidf)\n",
        "\n",
        "# AdaBoost Reduced\n",
        "ada = AdaBoostClassifier(n_estimators=100, random_state=SEED)\n",
        "ada.fit(X_train_reduced, y_train)\n",
        "pred_ada = ada.predict(X_val_reduced)"
      ],
      "metadata": {
        "id": "SxHciU75EEZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBoost\n",
        "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', n_estimators=100, random_state=SEED)\n",
        "# XGBoost can accept sparse matrix directly; handling class weights manually if needed\n",
        "if BALANCE_CLASSES:\n",
        "    sample_w = np.array([class_weights[label] for label in y_train])\n",
        "    xgb.fit(X_train_tfidf, y_train, sample_weight=sample_w)\n",
        "else:\n",
        "    xgb.fit(X_train_tfidf, y_train)\n",
        "pred_xgb = xgb.predict(X_val_tfidf)\n",
        "model_performance['XGBoost'] = {\n",
        "    \"F1_weighted\": f1_score(y_val, pred_xgb, average='weighted'),\n",
        "    \"Accuracy\": accuracy_score(y_val, pred_xgb)\n",
        "}\n"
      ],
      "metadata": {
        "id": "VLQJCImn0KtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LightGBM\n",
        "lgb = LGBMClassifier(n_estimators=100, class_weight=('balanced' if BALANCE_CLASSES else None), random_state=SEED)\n",
        "lgb.fit(X_train_tfidf, y_train)\n",
        "pred_lgb = lgb.predict(X_val_tfidf)\n",
        "model_performance['LightGBM'] = {\n",
        "    \"F1_weighted\": f1_score(y_val, pred_lgb, average='weighted'),\n",
        "    \"Accuracy\": accuracy_score(y_val, pred_lgb)\n",
        "}"
      ],
      "metadata": {
        "id": "b3Icmtlx0OwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_performance"
      ],
      "metadata": {
        "id": "FpZIjyuM5qVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 Neural Network Models (CNN, LSTM)"
      ],
      "metadata": {
        "id": "TVqkSWq_kxy5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we build and train a Convolutional Neural Network and an LSTM Recurrent Network for text classification. We'll use the sequence data (X_train_seq) and their corresponding labels.\n",
        "\n",
        "Before training, we prepare labels for Keras:\n",
        "- Use 0-4 as class indices (we can subtract 1 from original y).\n",
        "- Use class_weights if balancing."
      ],
      "metadata": {
        "id": "AYurKL9Gk27U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare labels for Keras (0-indexed)\n",
        "y_train_keras = (y_train - 1)\n",
        "y_val_keras = (y_val - 1)\n",
        "num_classes = 5  # ratings 1-5\n",
        "\n",
        "# Convert labels to categorical if needed (for categorical_crossentropy). We'll use sparse crossentropy so not needed to one-hot.\n",
        "# y_train_cat = tf.keras.utils.to_categorical(y_train_keras, num_classes)\n",
        "# y_val_cat = tf.keras.utils.to_categorical(y_val_keras, num_classes)\n"
      ],
      "metadata": {
        "id": "cwUldKRhk6Jc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a simple CNN model for text classification:"
      ],
      "metadata": {
        "id": "PInLX5Etk9mM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_cnn_model(vocab_size, seq_length, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Embedding(MAX_VOCAB_SIZE, 128, input_length=MAX_SEQ_LENGTH),\n",
        "        layers.Conv1D(128, 5, activation='relu', padding='same'),\n",
        "        layers.GlobalMaxPooling1D(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "    model.compile(\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        optimizer=optimizers.Adam(learning_rate=1e-4),  # Lower LR\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "cnn_model = build_cnn_model(vocab_size=MAX_VOCAB_SIZE, seq_length=MAX_SEQ_LENGTH, num_classes=num_classes)\n",
        "cnn_model.build(input_shape=(None, MAX_SEQ_LENGTH))\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "id": "R8oh4bC7k8mu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "c58be3a7-a923-49d4-ce93-6b4c5b58e779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning:\n",
            "\n",
            "Argument `input_length` is deprecated. Just remove it.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m\n",
              "\n",
              " embedding (\u001b[38;5;33mEmbedding\u001b[0m)                 (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                   \u001b[38;5;34m2,560,000\u001b[0m \n",
              "\n",
              " conv1d (\u001b[38;5;33mConv1D\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)                      \u001b[38;5;34m82,048\u001b[0m \n",
              "\n",
              " global_max_pooling1d                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              " (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                                                               \n",
              "\n",
              " dropout (\u001b[38;5;33mDropout\u001b[0m)                     (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                                \u001b[38;5;34m0\u001b[0m \n",
              "\n",
              " dense (\u001b[38;5;33mDense\u001b[0m)                         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                             \u001b[38;5;34m8,256\u001b[0m \n",
              "\n",
              " dense_1 (\u001b[38;5;33mDense\u001b[0m)                       (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                                \u001b[38;5;34m325\u001b[0m \n",
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\"> Layer (type)                         </span><span style=\"font-weight: bold\"> Output Shape                </span><span style=\"font-weight: bold\">         Param # </span>\n",
              "\n",
              " embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                 (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560,000</span> \n",
              "\n",
              " conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                      <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> \n",
              "\n",
              " global_max_pooling1d                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              " (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                                                               \n",
              "\n",
              " dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                     (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
              "\n",
              " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                             <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> \n",
              "\n",
              " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                                <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> \n",
              "\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,650,629\u001b[0m (10.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,650,629</span> (10.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,650,629\u001b[0m (10.11 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,650,629</span> (10.11 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if BALANCE_CLASSES:\n",
        "    classes_keras = np.unique(y_train_keras)  # [0,1,2,3,4]\n",
        "    cw = class_weight.compute_class_weight('balanced',\n",
        "                                         classes=classes_keras,\n",
        "                                         y=y_train_keras)\n",
        "    class_weights = {cls: weight for cls, weight in zip(classes_keras, cw)}"
      ],
      "metadata": {
        "id": "Hi9SS3sAZGQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the CNN model on the training sequences and evaluate on the validation set:"
      ],
      "metadata": {
        "id": "RNjT0qablBDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the CNN model\n",
        "epochs = 8\n",
        "cnn_history = cnn_model.fit(X_train_seq, y_train_keras,\n",
        "                            epochs=epochs, batch_size=128,\n",
        "                            validation_data=(X_val_seq, y_val_keras),\n",
        "                            class_weight=(class_weights if BALANCE_CLASSES else None),\n",
        "                            verbose=1)\n",
        "# Evaluate on validation set\n",
        "cnn_val_preds = cnn_model.predict(X_val_seq).argmax(axis=1)\n",
        "model_performance['CNN (1D)'] = {\n",
        "    \"F1_weighted\": f1_score(y_val_keras, cnn_val_preds, average='weighted'),\n",
        "    \"Accuracy\": accuracy_score(y_val_keras, cnn_val_preds)\n",
        "}\n",
        "print(\"CNN model validation accuracy: {:.4f}\".format(model_performance['CNN (1D)']['Accuracy']))\n"
      ],
      "metadata": {
        "id": "QNxKeJA4lDi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, define and train an LSTM-based model:"
      ],
      "metadata": {
        "id": "Nn9_kfWolEz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_lstm_model(vocab_size, seq_length, num_classes):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Embedding(input_dim=vocab_size, output_dim=128, mask_zero=True))\n",
        "    model.add(layers.LSTM(128))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "lstm_model = build_lstm_model(vocab_size=MAX_VOCAB_SIZE, seq_length=MAX_SEQ_LENGTH, num_classes=num_classes)\n",
        "# Train LSTM model\n",
        "lstm_history = lstm_model.fit(X_train_seq, y_train_keras,\n",
        "                              epochs=3, batch_size=128,\n",
        "                              validation_data=(X_val_seq, y_val_keras),\n",
        "                              class_weight=(class_weights if BALANCE_CLASSES else None),\n",
        "                              verbose=1)\n",
        "# Evaluate on validation\n",
        "lstm_val_preds = lstm_model.predict(X_val_seq).argmax(axis=1)\n",
        "model_performance['LSTM'] = {\n",
        "    \"F1_weighted\": f1_score(y_val_keras, lstm_val_preds, average='weighted'),\n",
        "    \"Accuracy\": accuracy_score(y_val_keras, lstm_val_preds)\n",
        "}\n",
        "print(\"LSTM model validation accuracy: {:.4f}\".format(model_performance['LSTM']['Accuracy']))\n"
      ],
      "metadata": {
        "id": "ygdAPJkjlFq1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e19b36b7-3a38-4b31-ef32-491fbadd5e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m  12/1739\u001b[0m \u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.0546 - loss: nan"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node TensorScatterUpdate defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-32-73141d373df3>\", line 12, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 80, in train_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\", line 383, in apply_gradients\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 167, in apply\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 218, in _tf_apply\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 201, in _common_apply\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 254, in check_finite\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 254, in <listcomp>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/numpy.py\", line 3229, in isfinite\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/sparse.py\", line 338, in sparse_wrapper\n\nDetected at node TensorScatterUpdate defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-32-73141d373df3>\", line 12, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 80, in train_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\", line 383, in apply_gradients\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 167, in apply\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 218, in _tf_apply\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 201, in _common_apply\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 254, in check_finite\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 254, in <listcomp>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/numpy.py\", line 3229, in isfinite\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/sparse.py\", line 338, in sparse_wrapper\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  indices[7401] = [20000] does not index into shape [20000,128]\n\t [[{{node TensorScatterUpdate}}]]\n\t [[StatefulPartitionedCall/TensorScatterUpdate/_34]]\n  (1) INVALID_ARGUMENT:  indices[7401] = [20000] does not index into shape [20000,128]\n\t [[{{node TensorScatterUpdate}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_2915]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-73141d373df3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_lstm_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_VOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_SEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Train LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m lstm_history = lstm_model.fit(X_train_seq, y_train_keras,\n\u001b[0m\u001b[1;32m     13\u001b[0m                               \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_keras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node TensorScatterUpdate defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-32-73141d373df3>\", line 12, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 80, in train_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\", line 383, in apply_gradients\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 167, in apply\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 218, in _tf_apply\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 201, in _common_apply\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 254, in check_finite\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 254, in <listcomp>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/numpy.py\", line 3229, in isfinite\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/sparse.py\", line 338, in sparse_wrapper\n\nDetected at node TensorScatterUpdate defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n\n  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 205, in start\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/usr/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n\n  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-32-73141d373df3>\", line 12, in <cell line: 0>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 371, in fit\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 219, in function\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 132, in multi_step_on_iterator\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 113, in one_step_on_data\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 80, in train_step\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\", line 383, in apply_gradients\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 167, in apply\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 218, in _tf_apply\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 201, in _common_apply\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 254, in check_finite\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/loss_scale_optimizer.py\", line 254, in <listcomp>\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/ops/numpy.py\", line 3229, in isfinite\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/sparse.py\", line 338, in sparse_wrapper\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  indices[7401] = [20000] does not index into shape [20000,128]\n\t [[{{node TensorScatterUpdate}}]]\n\t [[StatefulPartitionedCall/TensorScatterUpdate/_34]]\n  (1) INVALID_ARGUMENT:  indices[7401] = [20000] does not index into shape [20000,128]\n\t [[{{node TensorScatterUpdate}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_2915]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 Transformer Model Fine-Tuning (BERT/DistilBERT/ModernBERT)"
      ],
      "metadata": {
        "id": "Q9Sbg-D3lIi0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we fine-tune a transformer model for classification. We'll use Hugging Face's Trainer API for convenience.\n",
        "\n",
        "We define the model and training arguments:"
      ],
      "metadata": {
        "id": "6Dn7BOp1lO5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained transformer model for sequence classification\n",
        "transformer_model = AutoModelForSequenceClassification.from_pretrained(transformer_model_name, num_labels=5)\n",
        "# Use GPU if available\n",
        "if USE_GPU:\n",
        "    transformer_model.cuda()\n",
        "\n",
        "# Define training arguments for the Trainer\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./transformer_output\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    num_train_epochs=3,               # just 1 epoch for demonstration (increase for better performance)\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50,\n",
        "    report_to=\"none\",\n",
        "    disable_tqdm=False,\n",
        "    dataloader_num_workers=4 if USE_GPU else 0,\n",
        "    gradient_accumulation_steps=2 if USE_GPU else 1,\n",
        "    eval_accumulation_steps=2,\n",
        "    optim=\"adamw_torch_fused\" if USE_GPU else \"adamw_torch\",\n",
        "    fp16=USE_GPU,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "# Define a compute_metrics function to calculate F1 (weighted) and accuracy\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average='weighted')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"f1_weighted\": f1, \"accuracy\": acc}\n",
        "\n",
        "# Initialize Trainer\n",
        "trainer = Trainer(\n",
        "    model=transformer_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "# Evaluate on the validation set\n",
        "eval_results = trainer.evaluate()\n",
        "print(\"Transformer model validation results:\", eval_results)\n",
        "model_performance['Transformer (' + transformer_model_name + ')'] = {\n",
        "    \"F1_weighted\": eval_results.get(\"eval_f1_weighted\", None),\n",
        "    \"Accuracy\": eval_results.get(\"eval_accuracy\", None)\n",
        "}\n"
      ],
      "metadata": {
        "id": "8iyhfcKAlRAh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "7082761e-efce-4b78-ee3b-e0fa8fd35abf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at answerdotai/ModernBERT-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1611: FutureWarning:\n",
            "\n",
            "`evaluation_strategy` is deprecated and will be removed in version 4.46 of  Transformers. Use `eval_strategy` instead\n",
            "\n",
            "W0406 04:40:00.391000 34034 torch/_inductor/utils.py:1137] [1/0] Not enough SMs to use max_autotune_gemm mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13911' max='13911' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13911/13911 44:17, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.165100</td>\n",
              "      <td>0.545682</td>\n",
              "      <td>0.770134</td>\n",
              "      <td>0.788484</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3092' max='3092' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3092/3092 01:43]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer model validation results: {'eval_loss': 0.5456823110580444, 'eval_f1_weighted': 0.7701335255871661, 'eval_accuracy': 0.788484088795439, 'eval_runtime': 104.2326, 'eval_samples_per_second': 237.267, 'eval_steps_per_second': 29.664, 'epoch': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*(We limited training to 1 epoch for speed. In practice, 2-3 epochs or more might be needed to fully fine-tune. Also, ModernBERT can be used by setting transformer_model_name = \"answerdotai/ModernBERT-base\", which may yield better results given its improvements.)*"
      ],
      "metadata": {
        "id": "SQdQ7nlulUZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's summarize the model performances on the validation set:"
      ],
      "metadata": {
        "id": "730XZwu0lWlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show performance of all models\n",
        "performance_df = pd.DataFrame(model_performance).T  # transpose for easier reading\n",
        "performance_df = performance_df.sort_values(\"F1_weighted\", ascending=False)\n",
        "print(\"\\nValidation Set Performance (sorted by F1_score):\")\n",
        "display(performance_df)\n"
      ],
      "metadata": {
        "id": "4SGONFKKlW2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have metrics for over 10 different models. We will use the weighted F1-score as the primary metric to decide which models are performing best (since that was our target optimization metric).\n"
      ],
      "metadata": {
        "id": "BaqxXSDulZIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Hyperparameter Optimization"
      ],
      "metadata": {
        "id": "0xSAq50zlaHf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will perform hyperparameter tuning on some of the promising models to further improve performance. As an example, let's tune the hyperparameters of Logistic Regression and Random Forest using cross-validation on the training set. This is to demonstrate how one could systematically search for better parameters."
      ],
      "metadata": {
        "id": "OO6XMToile82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 Tuning Logistic Regression\n",
        "We'll try different values for the regularization strength C and see if a different value improves weighted F1."
      ],
      "metadata": {
        "id": "Q8N7NIptlf0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning for Logistic Regression\n",
        "param_grid_lr = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'class_weight': ['balanced'] if BALANCE_CLASSES else [None]\n",
        "}\n",
        "grid_lr = GridSearchCV(LogisticRegression(max_iter=200, random_state=SEED), param_grid_lr,\n",
        "                       scoring='f1_weighted', cv=3, n_jobs=-1)\n",
        "grid_lr.fit(X_train_tfidf, y_train)\n",
        "print(\"Best LogisticRegression params:\", grid_lr.best_params_)\n",
        "print(\"Best CV weighted F1:\", grid_lr.best_score_)\n"
      ],
      "metadata": {
        "id": "MKSLjFzYlkVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2 Tuning Random Forest\n",
        "We'll search over number of trees and maximum depth:"
      ],
      "metadata": {
        "id": "x-4UZ_EFllkb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning for Random Forest\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'class_weight': ['balanced'] if BALANCE_CLASSES else [None]\n",
        "}\n",
        "rand_rf = RandomizedSearchCV(RandomForestClassifier(random_state=SEED), param_grid_rf,\n",
        "                             n_iter=5, scoring='f1_weighted', cv=3, random_state=SEED, n_jobs=-1)\n",
        "rand_rf.fit(X_train_tfidf, y_train)\n",
        "print(\"Best RandomForest params:\", rand_rf.best_params_)\n",
        "print(\"Best CV weighted F1:\", rand_rf.best_score_)\n"
      ],
      "metadata": {
        "id": "QgRpD-p9lqCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***IMPORTANT TO DO: retrain the model with the best parameters on the full training data and then evaluate again on the validation set or test set to see the improvement. ***"
      ],
      "metadata": {
        "id": "DK1WuBLXlvmH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Ensemble Architectures\n",
        "Ensembles can often improve performance by combining the strengths of multiple models. We will create an ensemble of some of the best-performing individual models from our model zoo. We explore two approaches:\n",
        "- Voting Ensemble: A simple approach where each model votes on the class (hard voting) or averages predicted probabilities (soft voting).\n",
        "- Stacking Ensemble: A meta-model is trained on the outputs of base models.\n",
        "\n",
        "For simplicity, let's do a soft voting ensemble with a few top models (for example, Logistic Regression, XGBoost, and our Transformer model). We'll also demonstrate a stacking ensemble using scikit-learn's StackingClassifier."
      ],
      "metadata": {
        "id": "dSq2Ud0xl2FX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we'll build a voting classifier with some models:"
      ],
      "metadata": {
        "id": "aVp6uJlGmBd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Voting ensemble of top models (using soft voting)\n",
        "# We'll include Logistic Regression, Random Forest, and XGBoost as an example\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[('lr', logreg), ('rf', rf), ('xgb', xgb)],\n",
        "    voting='soft'\n",
        ")\n",
        "voting_clf.fit(X_train_tfidf, y_train)\n",
        "voting_preds = voting_clf.predict(X_val_tfidf)\n",
        "model_performance['Voting Ensemble'] = {\n",
        "    \"F1_weighted\": f1_score(y_val, voting_preds, average='weighted'),\n",
        "    \"Accuracy\": accuracy_score(y_val, voting_preds)\n",
        "}\n",
        "print(\"Voting Ensemble F1 (val):\", model_performance['Voting Ensemble']['F1_weighted'])\n"
      ],
      "metadata": {
        "id": "7_kchS5cmCUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, a stacking ensemble. We'll use logistic regression as the meta-classifier on top of (Logistic Regression, XGBoost, LightGBM) to combine their predictions:"
      ],
      "metadata": {
        "id": "WKJvYm6qmDsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stacking ensemble\n",
        "base_models = [('lr', logreg), ('xgb', xgb), ('lgb', lgb)]\n",
        "\n",
        "meta_features = []\n",
        "for name, model in base_models:\n",
        "    cv_preds = cross_val_predict(model, X_train_tfidf, y_train,\n",
        "                               cv=3, method='predict_proba',\n",
        "                               n_jobs=-1)\n",
        "    meta_features.append(cv_preds)\n",
        "\n",
        "X_meta = np.hstack(meta_features)\n",
        "\n",
        "# Train meta-learner on cross-validated predictions\n",
        "meta_learner = LogisticRegression()\n",
        "meta_learner.fit(X_meta, y_train)\n",
        "\n",
        "# Final stacking classifier\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=base_models,\n",
        "    final_estimator=meta_learner,\n",
        "    passthrough=False\n",
        ")\n",
        "\n",
        "stacking_preds = stacking_clf.predict(X_val_tfidf)\n",
        "model_performance['Stacking Ensemble'] = {\n",
        "    \"F1_weighted\": f1_score(y_val, stacking_preds, average='weighted'),\n",
        "    \"Accuracy\": accuracy_score(y_val, stacking_preds)\n",
        "}\n",
        "print(\"Stacking Ensemble F1 (val):\", model_performance['Stacking Ensemble']['F1_weighted'])\n"
      ],
      "metadata": {
        "id": "XgGM8-uFmElO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*(The stacking classifier by default uses cross-validation on the training set to generate predictions for the meta-model, so we can train it on the entire training set without using the validation data.)*"
      ],
      "metadata": {
        "id": "MsHLS_C9mGCm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now update our performance summary with the ensemble results:"
      ],
      "metadata": {
        "id": "q5NU_PABmHwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "performance_df = pd.DataFrame(model_performance).T\n",
        "performance_df = performance_df.sort_values(\"F1_weighted\", ascending=False)\n",
        "print(\"\\nUpdated Model Performance with Ensembles:\")\n",
        "display(performance_df)\n"
      ],
      "metadata": {
        "id": "PsiKfnIomJha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Experiment Tracking and Metrics Storage\n",
        "Throughout our model training process, we have been tracking metrics in the model_performance dictionary. We can easily convert this to a DataFrame (as done above) and even save it to disk for record-keeping. This ensures we have a summary of how each model performed."
      ],
      "metadata": {
        "id": "WoiNiBVKmMkf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save the metrics to a CSV file for reference, and also print out a summary table of the best models:"
      ],
      "metadata": {
        "id": "ZL_-jE3imRqF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save performance metrics to CSV\n",
        "performance_df.to_csv(\"model_performance_summary.csv\", index=True)\n",
        "\n",
        "# Display top 5 models by weighted F1 score\n",
        "print(\"Top 5 models by weighted F1 on validation set:\")\n",
        "display(performance_df.head(5))\n"
      ],
      "metadata": {
        "id": "Ryw_E4vFmS8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a more sophisticated tracking, one could integrate libraries like Weights & Biases (wandb) or MLflow to log parameters, metrics, and even model artifacts. In this notebook, we kept it simple with a dictionary and CSV logging."
      ],
      "metadata": {
        "id": "y2C0AFsfmUta"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***IMPORTANT TO DO: (All experiments were run with the same training/validation split for comparability. If more rigor is needed, consider cross-validation for each model evaluation to mitigate variance due to a single split.)***"
      ],
      "metadata": {
        "id": "MBENpergmVKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Submission Preparation"
      ],
      "metadata": {
        "id": "vKDfRqxbme4k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we prepare the model to generate predictions on the test set and create the submission file. In a real Kaggle competition, the test set labels are unknown, and we only submit the features (e.g., an ID and the predicted score). Here, since we made our own train/test split, we do have the labels for our test set; we will simulate a submission and also evaluate the performance on this held-out test for completeness."
      ],
      "metadata": {
        "id": "PfFbk90YminM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.1 Choose the final model\n",
        "Based on validation performance, let's select the best model (highest weighted F1). We'll use that model to predict on the test set. For demonstration, let's assume the stacking ensemble gave the best validation F1 (but we'll determine this dynamically from our performance_df)."
      ],
      "metadata": {
        "id": "qyL7pJ0ymi7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the best model based on validation F1\n",
        "best_model_name = performance_df.index[0]\n",
        "print(\"Best model based on validation F1:\", best_model_name)\n",
        "\n",
        "# Use the best model for final predictions\n",
        "best_model = None\n",
        "if best_model_name == 'Logistic Regression':\n",
        "    best_model = logreg\n",
        "elif best_model_name == 'Linear SVM':\n",
        "    best_model = svm\n",
        "elif best_model_name == 'Multinomial NB':\n",
        "    best_model = nb\n",
        "elif best_model_name == 'Random Forest':\n",
        "    best_model = rf\n",
        "elif best_model_name == 'AdaBoost':\n",
        "    best_model = ada\n",
        "elif best_model_name == 'XGBoost':\n",
        "    best_model = xgb\n",
        "elif best_model_name == 'LightGBM':\n",
        "    best_model = lgb\n",
        "elif best_model_name == 'CNN (1D)':\n",
        "    best_model = cnn_model\n",
        "elif best_model_name == 'LSTM':\n",
        "    best_model = lstm_model\n",
        "elif best_model_name.startswith('Transformer'):\n",
        "    best_model = transformer_model  # HuggingFace model\n",
        "elif best_model_name == 'Voting Ensemble':\n",
        "    best_model = voting_clf\n",
        "elif best_model_name == 'Stacking Ensemble':\n",
        "    best_model = stacking_clf\n",
        "\n",
        "# If the best model is an sklearn model or stacking/voting, retrain on full training data (train+val) for final model\n",
        "X_full_train_tfidf = tfidf_vectorizer.fit_transform(pd.concat([train_df['clean_text'], val_df['clean_text']]))\n",
        "y_full_train = pd.concat([train_df['Score'], val_df['Score']]).astype(int).values\n",
        "\n",
        "if best_model_name in ['Logistic Regression','Linear SVM','Random Forest','AdaBoost','XGBoost','LightGBM']:\n",
        "    # Retrain best model on full train+val dataset\n",
        "    if best_model_name == 'Logistic Regression':\n",
        "        best_model = LogisticRegression(max_iter=200, class_weight=('balanced' if BALANCE_CLASSES else None), random_state=SEED)\n",
        "    elif best_model_name == 'Linear SVM':\n",
        "        best_model = SVC(kernel='linear', class_weight=('balanced' if BALANCE_CLASSES else None), probability=True, random_state=SEED)\n",
        "    elif best_model_name == 'Random Forest':\n",
        "        best_model = RandomForestClassifier(n_estimators=100, class_weight=('balanced' if BALANCE_CLASSES else None), random_state=SEED)\n",
        "    elif best_model_name == 'AdaBoost':\n",
        "        best_model = AdaBoostClassifier(n_estimators=100, random_state=SEED)\n",
        "    elif best_model_name == 'XGBoost':\n",
        "        best_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', n_estimators=100, random_state=SEED)\n",
        "    elif best_model_name == 'LightGBM':\n",
        "        best_model = LGBMClassifier(n_estimators=100, class_weight=('balanced' if BALANCE_CLASSES else None), random_state=SEED)\n",
        "    # Fit on full training data\n",
        "    if best_model_name == 'XGBoost' and BALANCE_CLASSES:\n",
        "        sample_w_full = np.array([class_weights[label] for label in y_full_train])\n",
        "        best_model.fit(X_full_train_tfidf, y_full_train, sample_weight=sample_w_full)\n",
        "    else:\n",
        "        # Convert to dense if needed for AdaBoost\n",
        "        X_train_fit = X_full_train_tfidf if best_model_name != 'AdaBoost' else X_full_train_tfidf.toarray()\n",
        "        best_model.fit(X_train_fit, y_full_train)\n",
        "elif best_model_name in ['Voting Ensemble', 'Stacking Ensemble']:\n",
        "    # Re-create and retrain ensemble on full data\n",
        "    if best_model_name == 'Voting Ensemble':\n",
        "        best_model = VotingClassifier(\n",
        "            estimators=[('lr', LogisticRegression(max_iter=200, class_weight=('balanced' if BALANCE_CLASSES else None), random_state=SEED)),\n",
        "                        ('rf', RandomForestClassifier(n_estimators=100, class_weight=('balanced' if BALANCE_CLASSES else None), random_state=SEED)),\n",
        "                        ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', n_estimators=100, random_state=SEED))],\n",
        "            voting='soft'\n",
        "        )\n",
        "        # Fit ensemble (handle XGB weighting if needed)\n",
        "        if BALANCE_CLASSES:\n",
        "            sample_w_full = np.array([class_weights[label] for label in y_full_train])\n",
        "            best_model.fit(X_full_train_tfidf, y_full_train, sample_weight=sample_w_full)\n",
        "        else:\n",
        "            best_model.fit(X_full_train_tfidf, y_full_train)\n",
        "    else:  # Stacking Ensemble\n",
        "        best_model = StackingClassifier(\n",
        "            estimators=[('lr', LogisticRegression(max_iter=200, class_weight=('balanced' if BALANCE_CLASSES else None), random_state=SEED)),\n",
        "                        ('xgb', XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', n_estimators=100, random_state=SEED)),\n",
        "                        ('lgb', LGBMClassifier(n_estimators=100, class_weight=('balanced' if BALANCE_CLASSES else None), random_state=SEED))],\n",
        "            final_estimator=LogisticRegression(class_weight=('balanced' if BALANCE_CLASSES else None), random_state=SEED)\n",
        "        )\n",
        "        best_model.fit(X_full_train_tfidf, y_full_train)\n",
        "elif best_model_name.startswith('Transformer'):\n",
        "    # If transformer is best, we would fine-tune it on the combined train+val set for final model\n",
        "    # (For simplicity, we reuse the already fine-tuned model from earlier without re-training)\n",
        "    pass\n",
        "elif best_model_name in ['CNN (1D)', 'LSTM']:\n",
        "    # If CNN/LSTM best, ideally retrain on full data. For simplicity, reuse trained model.\n",
        "    pass\n"
      ],
      "metadata": {
        "id": "m0cQpXLAmmhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10.2 Predict on Test set and prepare submission"
      ],
      "metadata": {
        "id": "sFNXH92Umn-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we generate predictions on the test set using the selected model. We will then create a DataFrame with an ID and the predicted Score. If an ID is not present in the dataset, we'll use the DataFrame index as the ID for submission."
      ],
      "metadata": {
        "id": "WyU_PGFWms7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare test features for the chosen model\n",
        "# We need to transform test data consistently with what we trained on.\n",
        "X_test_final = X_test_tfidf  # default assume using tfidf for sklearn models\n",
        "if best_model_name in ['AdaBoost']:\n",
        "    X_test_final = X_test_tfidf.toarray()  # AdaBoost was trained on dense\n",
        "# (For CNN/LSTM/Transformer, we have X_test_seq or test_dataset prepared)\n",
        "\n",
        "# Make predictions\n",
        "if best_model_name in ['CNN (1D)', 'LSTM']:\n",
        "    test_preds = best_model.predict(X_test_seq).argmax(axis=1) + 1  # +1 to convert 0-index to 1-5 scale\n",
        "elif best_model_name.startswith('Transformer'):\n",
        "    # Use Huggingface trainer for prediction if transformer\n",
        "    transformer_outputs = trainer.predict(test_dataset)\n",
        "    test_preds = transformer_outputs.predictions.argmax(axis=1) + 1\n",
        "else:\n",
        "    test_preds = best_model.predict(X_test_final)\n",
        "    # Ensure predictions are in 1-5 range (sklearn models already predict original labels)\n",
        "    # If any model predicted 0-4, add 1:\n",
        "    if test_preds.min() == 0 and test_preds.max() == 4:\n",
        "        test_preds = test_preds + 1\n",
        "\n",
        "# Evaluate on test set (since we have ground truth for our split)\n",
        "y_test = test_df['Score'].astype(int).values\n",
        "test_f1 = f1_score(y_test, test_preds, average='weighted')\n",
        "test_acc = accuracy_score(y_test, test_preds)\n",
        "print(f\"Final model performance on held-out test set: F1_weighted={test_f1:.4f}, Accuracy={test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "XvFQsuD7mtso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, prepare the submission file:"
      ],
      "metadata": {
        "id": "qYUDnabemvWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create submission DataFrame\n",
        "# If the original dataset has an ID column (like ReviewID), use that. Otherwise, use the index.\n",
        "if 'Id' in test_df.columns:\n",
        "    submission = pd.DataFrame({'Id': test_df['Id'], 'Score': test_preds})\n",
        "else:\n",
        "    submission = pd.DataFrame({'Id': test_df.index, 'Score': test_preds})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Submission file 'submission.csv' is ready!\")\n",
        "submission.head()\n"
      ],
      "metadata": {
        "id": "dsneDq-9mwEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This submission file contains the predicted star rating (Score) for each review in the test set, associated with an Id. In a Kaggle competition, we would upload this file to get the final evaluation on the leaderboard."
      ],
      "metadata": {
        "id": "VEw-h1CamxKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclusion: We built a comprehensive pipeline including data cleaning, feature engineering with multiple methods, a variety of models, hyperparameter tuning, and ensembling. By tracking the performance of each model, we selected the best approach for final predictions. This notebook can be further extended with more in-depth tuning, cross-validation, and analysis to push the model performance even higher."
      ],
      "metadata": {
        "id": "qWjQHzEwmyZs"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "L4",
      "history_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bea90ea2f2bd4ee195f8f3723c809245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c010633ea8244a28ac5753668e19f4c9",
              "IPY_MODEL_9bffde794062408a9202f2425862ae1c",
              "IPY_MODEL_03f1c07ab2a2497b8be974df3f84dc03"
            ],
            "layout": "IPY_MODEL_5e85157d2053449d8d63e34240863b22"
          }
        },
        "fc924b1a096d472cb1fca2c01112a21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4208bbae89214fb79dd7ecf2afb420dc",
              "IPY_MODEL_f9a8e22432a142c2ba4fba4640543084",
              "IPY_MODEL_ff961ec92f9b4d2b9bf2e57da309b052"
            ],
            "layout": "IPY_MODEL_ede23b911d6d4118be9cce9241bdb0f5"
          }
        },
        "c010633ea8244a28ac5753668e19f4c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fc47f238412465b90b4d57567cc9806",
            "placeholder": "",
            "style": "IPY_MODEL_1480688c7d2a4444a61769810ec19a0e",
            "value": "tokenizer_config.json:100%"
          }
        },
        "9bffde794062408a9202f2425862ae1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43a9827a18424bdca4230fb21e5e872a",
            "max": 20810,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5015382a8144478c8d3845194ff2f309",
            "value": 20810
          }
        },
        "03f1c07ab2a2497b8be974df3f84dc03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_380a4a92a82d4fa788ab02d82fb1f748",
            "placeholder": "",
            "style": "IPY_MODEL_4d06f04257dc4de38c6bcdda5ddfb656",
            "value": "20.8k/20.8k[00:00&lt;00:00,2.33MB/s]"
          }
        },
        "5e85157d2053449d8d63e34240863b22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fc47f238412465b90b4d57567cc9806": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1480688c7d2a4444a61769810ec19a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43a9827a18424bdca4230fb21e5e872a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5015382a8144478c8d3845194ff2f309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "380a4a92a82d4fa788ab02d82fb1f748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d06f04257dc4de38c6bcdda5ddfb656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4208bbae89214fb79dd7ecf2afb420dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a28eb62554c4970bb255f63bc8788af",
            "placeholder": "",
            "style": "IPY_MODEL_dfa630f0f1bf402c89c2054cf14dfaa8",
            "value": "tokenizer.json:100%"
          }
        },
        "f9a8e22432a142c2ba4fba4640543084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_250854eb67b7406db664979c7f281fa7",
            "max": 2132967,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bdd067d5e74407181526a9330998837",
            "value": 2132967
          }
        },
        "ff961ec92f9b4d2b9bf2e57da309b052": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b149f02565624f75a62de1113add960a",
            "placeholder": "",
            "style": "IPY_MODEL_5e055e7331314f63a8aa4510d15a1b4f",
            "value": "2.13M/2.13M[00:00&lt;00:00,36.4MB/s]"
          }
        },
        "ede23b911d6d4118be9cce9241bdb0f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a28eb62554c4970bb255f63bc8788af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfa630f0f1bf402c89c2054cf14dfaa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "250854eb67b7406db664979c7f281fa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bdd067d5e74407181526a9330998837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b149f02565624f75a62de1113add960a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e055e7331314f63a8aa4510d15a1b4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ea588a5cef44177b6618ed46912767b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aafb28a643e747f881f0924a054d9545",
              "IPY_MODEL_926204ffde13445b98dd8d5f17e3c729",
              "IPY_MODEL_ffc78ca0896f4291badcf5dafc6aab35"
            ],
            "layout": "IPY_MODEL_5bb639e692a04f0eb642fb774baca649"
          }
        },
        "aafb28a643e747f881f0924a054d9545": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcc046f5fd7844ffacbaad103e50ce77",
            "placeholder": "",
            "style": "IPY_MODEL_a564e4da9b8e440987a1d0a3a01b4461",
            "value": "special_tokens_map.json:100%"
          }
        },
        "926204ffde13445b98dd8d5f17e3c729": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_736392b2689e455ea088f81fbc189320",
            "max": 694,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba32cdd6e79547869043f2ac7b003e52",
            "value": 694
          }
        },
        "ffc78ca0896f4291badcf5dafc6aab35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fb18d01222b446ba0c7acab4361458b",
            "placeholder": "",
            "style": "IPY_MODEL_77dc0dfbdbcf4a3cb09c22858ba30730",
            "value": "694/694[00:00&lt;00:00,94.0kB/s]"
          }
        },
        "5bb639e692a04f0eb642fb774baca649": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcc046f5fd7844ffacbaad103e50ce77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a564e4da9b8e440987a1d0a3a01b4461": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "736392b2689e455ea088f81fbc189320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba32cdd6e79547869043f2ac7b003e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fb18d01222b446ba0c7acab4361458b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77dc0dfbdbcf4a3cb09c22858ba30730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}